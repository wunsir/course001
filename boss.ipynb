{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34458947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŽ¥å£è¿”å›ž code: 0  message: Success\n",
      "jobList é•¿åº¦: 30\n",
      "\n",
      "ç¤ºä¾‹èŒä½ï¼ˆæœ€å¤š 5 æ¡ï¼‰ï¼š\n",
      "--- #1 ---\n",
      "èŒä½: é«˜çº§pythonå·¥ç¨‹å¸ˆ\n",
      "å…¬å¸: çµåŒ ç§‘æŠ€\n",
      "è–ªèµ„: 25-50KÂ·13è–ª\n",
      "åœ°åŒº: å—äº¬\n",
      "è¡Œä¸š: äº’è”ç½‘\n",
      "encryptJobId: bdea2528354bab7f03J72N68EVtS\n",
      "\n",
      "--- #2 ---\n",
      "èŒä½: é«˜çº§å¤§æ•°æ®å¼€å‘å·¥ç¨‹å¸ˆï¼ˆpythonï¼‰\n",
      "å…¬å¸: æžè”è‚¡ä»½\n",
      "è–ªèµ„: 8-12K\n",
      "åœ°åŒº: å“ˆå°”æ»¨\n",
      "è¡Œä¸š: è®¡ç®—æœºè½¯ä»¶\n",
      "encryptJobId: 5d2b0feae95c710603Bz3t68FlBW\n",
      "\n",
      "--- #3 ---\n",
      "èŒä½: é«˜çº§éŸ³è§†é¢‘å¼€å‘å·¥ç¨‹å¸ˆ\n",
      "å…¬å¸: ä¹‹æ±Ÿå®žéªŒå®¤\n",
      "è–ªèµ„: 40-70K\n",
      "åœ°åŒº: ç æµ·\n",
      "è¡Œä¸š: å­¦æœ¯/ç§‘ç ”\n",
      "encryptJobId: eb8061cbe68bc5e003xy2Nm_FFBY\n",
      "\n",
      "--- #4 ---\n",
      "èŒä½: pythoné«˜çº§å¼€å‘å·¥ç¨‹å¸ˆ\n",
      "å…¬å¸: åŒ—äº¬æµ·å¤©èµ·ç‚¹æŠ€æœ¯...\n",
      "è–ªèµ„: 13-14K\n",
      "åœ°åŒº: æ ªæ´²\n",
      "è¡Œä¸š: è®¡ç®—æœºè½¯ä»¶\n",
      "encryptJobId: 508c31c6025f6dc103x93tS9GVFY\n",
      "\n",
      "--- #5 ---\n",
      "èŒä½: pythonåŽç«¯å¼€å‘å·¥ç¨‹å¸ˆ\n",
      "å…¬å¸: æ¹˜æ½­ç³–å°¿ç—…åŒ»é™¢\n",
      "è–ªèµ„: 10-15K\n",
      "åœ°åŒº: æ¹˜æ½­\n",
      "è¡Œä¸š: åŒ»ç–—å¥åº·\n",
      "encryptJobId: 27f5518d198b4f4903d_3d6-EFVS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verify_boss.py\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "SEARCH_PAGE = \"https://www.zhipin.com/web/geek/job\"  # é¢„çƒ­é¡µ\n",
    "API_URL = \"https://www.zhipin.com/wapi/zpgeek/search/joblist.json\"\n",
    "\n",
    "def cookie_str_to_dict(cookie_str: str) -> dict:\n",
    "    jar = {}\n",
    "    for kv in cookie_str.split(';'):\n",
    "        kv = kv.strip()\n",
    "        if not kv or '=' not in kv:\n",
    "            continue\n",
    "        k, v = kv.split('=', 1)\n",
    "        jar[k.strip()] = v.strip()\n",
    "    return jar\n",
    "\n",
    "def verify_once(raw_cookie: str, query=\"Pythoné«˜çº§å¼€å‘å·¥ç¨‹å¸ˆ\", city=\"100010000\"):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.zhipin.com/\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9\",\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"scene\": \"1\",\n",
    "        \"query\": query,\n",
    "        \"city\": city,\n",
    "        \"experience\": \"106\",      # å¯æ”¹\n",
    "        \"scale\": \"303,304,305\",   # å¯æ”¹\n",
    "        \"page\": 1,\n",
    "        \"pageSize\": 30\n",
    "    }\n",
    "\n",
    "    sess = requests.Session()\n",
    "    sess.headers.update(headers)\n",
    "    sess.cookies.update(cookie_str_to_dict(raw_cookie))\n",
    "\n",
    "    # 1) é¢„çƒ­ï¼šå…ˆè®¿é—®æœç´¢é¡µï¼ˆGETï¼‰ï¼Œè®©æœåŠ¡ç«¯å¯èƒ½åˆ·æ–° Cookie / ä»¤ç‰Œ\n",
    "    try:\n",
    "        r = sess.get(SEARCH_PAGE, params={\"query\": params[\"query\"], \"city\": params[\"city\"]}, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        # ç»™æœåŠ¡å™¨ä¸€ç‚¹æ—¶é—´/èŠ‚å¥\n",
    "        time.sleep(random.uniform(0.8, 1.3))\n",
    "    except Exception as e:\n",
    "        print(\"é¢„çƒ­é¡µè®¿é—®å¤±è´¥ï¼š\", e)\n",
    "        # ä»ç»§ç»­å°è¯•è¯·æ±‚æŽ¥å£ï¼ˆæœ‰æ—¶å€™ä¸éœ€è¦é¢„çƒ­ä¹Ÿèƒ½æˆåŠŸï¼‰\n",
    "\n",
    "    # 2) çœŸæ­£ POST è¯·æ±‚ï¼ˆæŠŠå‚æ•°æ”¾åœ¨ bodyï¼‰\n",
    "    try:\n",
    "        resp = sess.post(API_URL, data=params, timeout=12)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(\"è¯·æ±‚ joblist æŽ¥å£å¤±è´¥ï¼š\", e)\n",
    "        return\n",
    "\n",
    "    # 3) è§£æžå¹¶å±•ç¤ºè¿”å›žå†…å®¹çš„å…³é”®ä¿¡æ¯\n",
    "    text_snip = resp.text[:800]\n",
    "    try:\n",
    "        j = resp.json()\n",
    "    except Exception as e:\n",
    "        print(\"è¿”å›žä¸æ˜¯ JSONï¼Œå¯èƒ½è¢«é£ŽæŽ§æˆ–ç™»å½•å¤±æ•ˆã€‚å‰800å­—ç¬¦å¦‚ä¸‹ï¼š\")\n",
    "        print(text_snip)\n",
    "        return\n",
    "\n",
    "    # æ‰“å°æŽ¥å£ code/message ä»¥åŠ jobList æƒ…å†µ\n",
    "    code = j.get(\"code\")\n",
    "    msg = j.get(\"message\") or j.get(\"msg\")\n",
    "    print(\"æŽ¥å£è¿”å›ž code:\", code, \" message:\", msg)\n",
    "\n",
    "    job_list = (j.get(\"zpData\") or {}).get(\"jobList\", [])\n",
    "    print(\"jobList é•¿åº¦:\", len(job_list))\n",
    "\n",
    "    if not job_list:\n",
    "        print(\"æ³¨æ„ï¼šjobList ä¸ºç©º â†’ å¯èƒ½ Cookie æ— æ•ˆ / æ¡ä»¶è¿‡çª„ / è¢«é£ŽæŽ§ã€‚\")\n",
    "        # æ‰“å°æ•´ä¸ªå“åº”çš„éƒ¨åˆ†å…³é”®å­—æ®µï¼Œä¾¿äºŽæŽ’æŸ¥\n",
    "        pprint.pprint({k: j.get(k) for k in (\"code\", \"message\", \"zpData\")})\n",
    "        return\n",
    "\n",
    "    # æ‰“å°å‰ 5 æ¡ç®€è¦ä¿¡æ¯\n",
    "    print(\"\\nç¤ºä¾‹èŒä½ï¼ˆæœ€å¤š 5 æ¡ï¼‰ï¼š\")\n",
    "    for i, job in enumerate(job_list[:5], 1):\n",
    "        print(f\"--- #{i} ---\")\n",
    "        print(\"èŒä½:\", job.get(\"jobName\"))\n",
    "        print(\"å…¬å¸:\", job.get(\"brandName\"))\n",
    "        print(\"è–ªèµ„:\", job.get(\"salaryDesc\"))\n",
    "        print(\"åœ°åŒº:\", job.get(\"cityName\"))\n",
    "        print(\"è¡Œä¸š:\", job.get(\"brandIndustry\"))\n",
    "        print(\"encryptJobId:\", job.get(\"encryptJobId\"))\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --------- æŠŠè¿™é‡Œæ›¿æ¢æˆä½ ä»Žæµè§ˆå™¨å¤åˆ¶çš„ Cookie å­—ç¬¦ä¸²ï¼ˆæ•´ä¸²ï¼‰ ----------\n",
    "    RAW_COOKIE = \"ab_guid=78d319c7-13e6-4a47-baf0-f120a7373d6f; wt2=D5HHFcwhyxdQ01sgtrmifW2zZ1rjjLskv6olsSpu45vNX08LSHmdAPpeS50jdaNEyYK8InyitQqt9sP68nx1Dow~~; wbg=0; zp_at=41c35eZXeQtAPNTeV030wsxJrGMPY2QsEsGV4gcKzSo~; __l=r=https%3A%2F%2Fwww.google.com%2F&l=%2Fnapi%2Fzpssrseo%2Fzhaopin%2F2d18dbe5285b5f040n172dq8%2F&s=1; __zp_seo_uuid__=60076b16-b36e-4ee7-a22d-3ffc5ea74c46; lastCity=100010000; __zp_stoken__=eeddfNjzDocK8wo3CuUEmEw4JCwdDJz08LW8%2FNihFN0M2PDc5RTY8Pxc3JhXCt0cmOWTDjDg8Kzw3RDw2Pjc3QRs8Q8S9wrc3PTDDjsK3RiY4X8OHCcKywrxZw7DCvQvDh8K8C8KTwrctwofCvCwqwonCvDc9Pzxjwrt2w4Fjwrh8w4M3PDw3PTcoOGFWYFg4N0pGWQpJXkdfZFULTlVVKT1ANjfCgsKmMjkSERMREggLCQsIFQ4UBwwMBw0HDAYNBw0GLzzCosK3wpvColQVw6bElsKdVMKfU8OswqfDhMKxxIJpw71ww7fCtMKkUFTDgcKKwrfCikjClsK8wr9MwrFecnRuXsK5f1NWaFVaV2RvblISZGVkXjgUWMKv; bst=V2R9MnF-L5219pVtRuyR8eKyO07DrWwCg~|R9MnF-L5219pVtRuyR8eKyO07DrVxiw~\"\n",
    "\n",
    "    # å¯æŠŠ query è®¾æˆ \"\" ä»¥å¹¿æ’’ç½‘æµ‹è¯•\n",
    "    verify_once(RAW_COOKIE, query=\"Pythoné«˜çº§å¼€å‘å·¥ç¨‹å¸ˆ\", city=\"100010000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a41f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ æ­£åœ¨é¢„çƒ­è¿žæŽ¥...\n",
      "\n",
      "ðŸ“„ æ­£åœ¨æŠ“å–åˆ—è¡¨ ç¬¬ 1 é¡µ ...\n",
      "âŒ è§¦å‘é£ŽæŽ§ (code: 37): æ‚¨çš„è®¿é—®è¡Œä¸ºå¼‚å¸¸.\n",
      "\n",
      "ðŸ’¡ å»ºè®®æ“ä½œï¼š\n",
      "   1. å·²é‡‡é›†æ•°æ®å°†è¢«ä¿å­˜\n",
      "   2. ç­‰å¾… 30-60 åˆ†é’ŸåŽé‡æ–°è¿è¡Œ\n",
      "   3. åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨æœç´¢èŒä½å¹¶æ›´æ–° Cookie\n",
      "   4. å½“å‰å·²è¯·æ±‚ 1 æ¬¡ï¼Œå»ºè®®ä¸‹æ¬¡å‡å°‘ max_collect\n",
      "\n",
      "âŒ æ²¡æœ‰é‡‡é›†åˆ°ç¬¦åˆæ¡ä»¶çš„èŒä½ã€‚\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "SEARCH_PAGE = \"https://www.zhipin.com/web/geek/job\"\n",
    "API_URL = \"https://www.zhipin.com/wapi/zpgeek/search/joblist.json\"\n",
    "\n",
    "# ====== å·²æ›´æ–°çš„ Cookie ======\n",
    "RAW_COOKIE = \"ab_guid=78d319c7-13e6-4a47-baf0-f120a7373d6f; wt2=D5HHFcwhyxdQ01sgtrmifW2zZ1rjjLskv6olsSpu45vNX08LSHmdAPpeS50jdaNEyYK8InyitQqt9sP68nx1Dow~~; wbg=0; zp_at=41c35eZXeQtAPNTeV030wsxJrGMPY2QsEsGV4gcKzSo~; __l=r=https%3A%2F%2Fwww.google.com%2F&l=%2Fnapi%2Fzpssrseo%2Fzhaopin%2F2d18dbe5285b5f040n172dq8%2F&s=1; __zp_seo_uuid__=60076b16-b36e-4ee7-a22d-3ffc5ea74c46; lastCity=100010000; __zp_stoken__=eeddfOTbDoMK8wofCtkMnExQGCQZDLTo2LCQ%2BOSpEN0E5NjY5Pzk2Phc9KQzCt8O6GDZew40bNiw2NkQ2OUQ2N0McNkLEvcK9ODcxOMK3w7wYOV%2FDjQbCsMK9WcOywroJw4bCvAnClMK9LMKHwrYrKDDCtz06RT1jwrl5w4Niwrh2w4Riwrl3w4M6PT08MzZjVmNZNj1KTVgMS15MXmJPC1VUUys9Qzc5woDCpjE4FBMTEhMGCQkICRMUFAwNCg0NDA0IBwcGBzE2wqTCvMO9w4bCqhXDrcSXwpvCsMKnXcOowrPEhUvCsFLDg3LCkV7CoWHCh07Ci3LCiMOBwrBfwrp%2FwpdjSFVRwoJZclJXZ8KCcHvCuEdwSBNiX2RlORLClnfDig%3D%3D; bst=V2R9MnF-L5219pVtRuyR8eKyO07DrTxyQ~|R9MnF-L5219pVtRuyR8eKyO07DrRxSU~\"# èŒä½å…³é”®è¯ï¼ˆç©º=ä¸é™ï¼‰\n",
    "QUERY = \"\"\n",
    "\n",
    "# é‡‘èžè¡Œä¸šå…³é”®è¯æ­£åˆ™\n",
    "FINANCE_PAT = re.compile(\n",
    "    r\"(é‡‘èž|é“¶è¡Œ|åˆ¸å•†|è¯åˆ¸|åŸºé‡‘|ä¿é™©|æœŸè´§|ä¿¡æ‰˜|æŠ•è¡Œ|èµ„ç®¡|ç†è´¢|è´¢å¯Œ|å°è´·|æ¶ˆé‡‘|ä¿ç†|ç§Ÿèµ|å¾ä¿¡|æ¸…ç®—|æ¸…ç»“ç®—|æ”¯ä»˜|äº’é‡‘|é‡‘èžç§‘æŠ€|FinTech)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# å¤šä¸ª User-Agent æ± ï¼ˆè½®æ¢ä½¿ç”¨ï¼‰\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15\"\n",
    "]\n",
    "\n",
    "def cookie_str_to_dict(cookie_str: str) -> dict:\n",
    "    \"\"\"å°† Cookie å­—ç¬¦ä¸²è½¬ä¸ºå­—å…¸\"\"\"\n",
    "    jar = {}\n",
    "    for kv in cookie_str.split(';'):\n",
    "        kv = kv.strip()\n",
    "        if not kv or '=' not in kv:\n",
    "            continue\n",
    "        k, v = kv.split('=', 1)\n",
    "        jar[k.strip()] = v.strip()\n",
    "    return jar\n",
    "\n",
    "def looks_like_finance(brand_industry: str, brand_name: str) -> bool:\n",
    "    \"\"\"åˆ¤æ–­æ˜¯å¦ä¸ºé‡‘èžç›¸å…³ï¼ˆè¡Œä¸šæˆ–å…¬å¸åå‘½ä¸­å³å¯ï¼‰\"\"\"\n",
    "    t1 = brand_industry or \"\"\n",
    "    t2 = brand_name or \"\"\n",
    "    return bool(FINANCE_PAT.search(t1)) or bool(FINANCE_PAT.search(t2))\n",
    "\n",
    "def get_random_headers() -> dict:\n",
    "    \"\"\"ç”Ÿæˆéšæœºè¯·æ±‚å¤´\"\"\"\n",
    "    return {\n",
    "        \"User-Agent\": random.choice(USER_AGENTS),\n",
    "        \"Referer\": \"https://www.zhipin.com/web/geek/job\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Origin\": \"https://www.zhipin.com\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"sec-ch-ua\": '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"sec-ch-ua-platform\": '\"Windows\"'\n",
    "    }\n",
    "\n",
    "def get_job_detail(sess: requests.Session, job_id: str) -> str:\n",
    "    \"\"\"èŽ·å–èŒä½è¯¦æƒ…æè¿°\"\"\"\n",
    "    if not job_id:\n",
    "        return \"\"\n",
    "    url = f\"https://www.zhipin.com/job_detail/{job_id}.html\"\n",
    "    try:\n",
    "        headers = get_random_headers()\n",
    "        r = sess.get(url, headers=headers, timeout=15)\n",
    "        if r.status_code != 200:\n",
    "            return \"\"\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        tag = soup.select_one(\".job-sec-text\") or soup.select_one(\".job-detail\") or soup.select_one(\".detail-content\")\n",
    "        return tag.get_text(strip=True) if tag else \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"è¯¦æƒ…é¡µèŽ·å–å¤±è´¥ ({job_id}): {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def exponential_backoff_sleep(attempt: int, base_min=3.0, base_max=6.0):\n",
    "    \"\"\"æŒ‡æ•°é€€é¿å»¶æ—¶ç­–ç•¥\"\"\"\n",
    "    multiplier = min(2 ** (attempt - 1), 8)  # æœ€å¤§ 8 å€\n",
    "    min_sleep = base_min * multiplier\n",
    "    max_sleep = base_max * multiplier\n",
    "    sleep_time = random.uniform(min_sleep, max_sleep)\n",
    "    print(f\"ðŸ’¤ ç­‰å¾… {sleep_time:.1f} ç§’ï¼ˆç¬¬ {attempt} æ¬¡è¯·æ±‚ï¼‰...\")\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "def run(max_collect=50, page_size=15, max_pages_soft=50):\n",
    "    \"\"\"\n",
    "    ä¸»é‡‡é›†å‡½æ•°ï¼ˆä¼˜åŒ–åçˆ¬ç­–ç•¥ï¼‰\n",
    "    \n",
    "    å‚æ•°:\n",
    "        max_collect: å•æ¬¡è¿è¡Œæœ€å¤§é‡‡é›†æ•°ï¼ˆå»ºè®®ä¸è¶…è¿‡ 50ï¼‰\n",
    "        page_size: æ¯é¡µæ•°é‡ï¼ˆé™ä½Žåˆ° 15ï¼‰\n",
    "        max_pages_soft: æœ€å¤§é¡µæ•°\n",
    "    \"\"\"\n",
    "    sess = requests.Session()\n",
    "    sess.cookies.update(cookie_str_to_dict(RAW_COOKIE))\n",
    "\n",
    "    # é¢„çƒ­ï¼šæ¨¡æ‹ŸçœŸå®žç”¨æˆ·å…ˆè®¿é—®æœç´¢é¡µ\n",
    "    print(\"ðŸ”¥ æ­£åœ¨é¢„çƒ­è¿žæŽ¥...\")\n",
    "    try:\n",
    "        headers = get_random_headers()\n",
    "        sess.headers.update(headers)\n",
    "        _ = sess.get(SEARCH_PAGE, params={\"query\": QUERY, \"city\": \"100010000\"}, timeout=15)\n",
    "        time.sleep(random.uniform(3.0, 5.0))  # é¢„çƒ­å»¶æ—¶å¢žåŠ åˆ° 3-5 ç§’\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ é¢„çƒ­å¤±è´¥ï¼ˆå¯ç»§ç»­ï¼‰: {e}\")\n",
    "\n",
    "    collected = []\n",
    "    seen_ids = set()\n",
    "    empty_hits = 0\n",
    "    request_count = 0\n",
    "\n",
    "    for page in range(1, max_pages_soft + 1):\n",
    "        if len(collected) >= max_collect:\n",
    "            print(f\"âœ… å·²è¾¾ç›®æ ‡æ•°é‡ {max_collect}ï¼Œåœæ­¢é‡‡é›†\")\n",
    "            break\n",
    "\n",
    "        form = {\n",
    "            \"scene\": \"1\",\n",
    "            \"query\": QUERY,\n",
    "            \"city\": \"100010000\",\n",
    "            \"page\": page,\n",
    "            \"pageSize\": page_size\n",
    "        }\n",
    "\n",
    "        print(f\"\\nðŸ“„ æ­£åœ¨æŠ“å–åˆ—è¡¨ ç¬¬ {page} é¡µ ...\")\n",
    "        \n",
    "        # æŒ‡æ•°é€€é¿å»¶æ—¶ï¼ˆç¬¬ 2 é¡µå¼€å§‹ï¼‰\n",
    "        if page > 1:\n",
    "            exponential_backoff_sleep(page)\n",
    "\n",
    "        try:\n",
    "            # æ¯æ¬¡è¯·æ±‚æ›´æ¢ User-Agent\n",
    "            headers = get_random_headers()\n",
    "            sess.headers.update(headers)\n",
    "            \n",
    "            resp = sess.post(API_URL, data=form, timeout=15)\n",
    "            resp.raise_for_status()\n",
    "            j = resp.json()\n",
    "            request_count += 1\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"âŒ HTTP é”™è¯¯: {e.response.status_code}\")\n",
    "            print(resp.text[:300])\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è¯·æ±‚å¼‚å¸¸: {e}\")\n",
    "            if hasattr(resp, 'text'):\n",
    "                print(resp.text[:300])\n",
    "            break\n",
    "\n",
    "        # æ£€æŸ¥è¿”å›žç \n",
    "        code = j.get(\"code\")\n",
    "        msg = j.get(\"message\") or j.get(\"msg\") or \"\"\n",
    "        \n",
    "        if code == 37:\n",
    "            print(f\"âŒ è§¦å‘é£ŽæŽ§ (code: 37): {msg}\")\n",
    "            print(\"\\nðŸ’¡ å»ºè®®æ“ä½œï¼š\")\n",
    "            print(\"   1. å·²é‡‡é›†æ•°æ®å°†è¢«ä¿å­˜\")\n",
    "            print(\"   2. ç­‰å¾… 30-60 åˆ†é’ŸåŽé‡æ–°è¿è¡Œ\")\n",
    "            print(\"   3. åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨æœç´¢èŒä½å¹¶æ›´æ–° Cookie\")\n",
    "            print(f\"   4. å½“å‰å·²è¯·æ±‚ {request_count} æ¬¡ï¼Œå»ºè®®ä¸‹æ¬¡å‡å°‘ max_collect\")\n",
    "            break\n",
    "        elif code not in (0, \"0\", None):\n",
    "            print(f\"âŒ æŽ¥å£å¼‚å¸¸ code: {code}, message: {msg}\")\n",
    "            break\n",
    "\n",
    "        # è§£æžèŒä½åˆ—è¡¨\n",
    "        job_list = (j.get(\"zpData\") or {}).get(\"jobList\", []) or []\n",
    "        if not job_list:\n",
    "            empty_hits += 1\n",
    "            print(f\"âš ï¸ æœ¬é¡µæ— æ•°æ®ï¼ˆè¿žç»­ç©ºé¡µ: {empty_hits}ï¼‰\")\n",
    "            if empty_hits >= 2:  # é™ä½Žåˆ° 2 æ¬¡å°±åœæ­¢\n",
    "                print(\"è¿žç»­å¤šé¡µæ— æ•°æ®ï¼Œç»“æŸé‡‡é›†\")\n",
    "                break\n",
    "            time.sleep(random.uniform(3.0, 5.0))\n",
    "            continue\n",
    "        \n",
    "        empty_hits = 0\n",
    "        print(f\"âœ… æœ¬é¡µèŽ·å–åˆ° {len(job_list)} ä¸ªèŒä½\")\n",
    "\n",
    "        # å¤„ç†æ¯ä¸ªèŒä½\n",
    "        finance_count = 0\n",
    "        for idx, job in enumerate(job_list, 1):\n",
    "            if len(collected) >= max_collect:\n",
    "                break\n",
    "\n",
    "            job_id = job.get(\"encryptJobId\")\n",
    "            if not job_id or job_id in seen_ids:\n",
    "                continue\n",
    "\n",
    "            brand_industry = (job.get(\"brandIndustry\") or \"\").strip()\n",
    "            brand_name = (job.get(\"brandName\") or \"\").strip()\n",
    "\n",
    "            # é‡‘èžè¡Œä¸šè¿‡æ»¤\n",
    "            if not looks_like_finance(brand_industry, brand_name):\n",
    "                continue\n",
    "\n",
    "            finance_count += 1\n",
    "            print(f\"  ðŸ’¼ [{finance_count}] {job.get('jobName')} - {brand_name}\")\n",
    "\n",
    "            # èŽ·å–è¯¦æƒ…ï¼ˆå»¶æ—¶å¢žåŠ åˆ° 4-8 ç§’ï¼‰\n",
    "            desc = get_job_detail(sess, job_id)\n",
    "            time.sleep(random.uniform(4.0, 8.0))\n",
    "\n",
    "            item = {\n",
    "                \"èŒä½\": job.get(\"jobName\"),\n",
    "                \"å…¬å¸\": brand_name,\n",
    "                \"è–ªèµ„\": job.get(\"salaryDesc\"),\n",
    "                \"åœ°åŒº\": job.get(\"cityName\"),\n",
    "                \"ç»éªŒ\": job.get(\"jobExperience\"),\n",
    "                \"å­¦åŽ†\": job.get(\"jobDegree\"),\n",
    "                \"å…¬å¸è§„æ¨¡\": job.get(\"brandScaleName\"),\n",
    "                \"è¡Œä¸š\": brand_industry,\n",
    "                \"ç¦åˆ©æ ‡ç­¾\": \",\".join(job.get(\"welfareList\", []) or []),\n",
    "                \"æŠ€èƒ½æ ‡ç­¾\": \",\".join(job.get(\"skills\", []) or []),\n",
    "                \"èŒä½æè¿°\": desc,\n",
    "                \"encryptJobId\": job_id\n",
    "            }\n",
    "\n",
    "            collected.append(item)\n",
    "            seen_ids.add(job_id)\n",
    "            request_count += 1\n",
    "\n",
    "        print(f\"ðŸ“Š æœ¬é¡µç¬¦åˆæ¡ä»¶: {finance_count} ä¸ª | å·²é‡‡é›†: {len(collected)}/{max_collect}\")\n",
    "\n",
    "    # ä¿å­˜ç»“æžœ\n",
    "    if not collected:\n",
    "        print(\"\\nâŒ æ²¡æœ‰é‡‡é›†åˆ°ç¬¦åˆæ¡ä»¶çš„èŒä½ã€‚\")\n",
    "        return\n",
    "\n",
    "    ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    fname = f\"å…¨å›½_é‡‘èžè¡Œä¸š_å²—ä½æ•°æ®_{ts}.xlsx\"\n",
    "    df = pd.DataFrame(collected)\n",
    "    df.drop(columns=[\"encryptJobId\"], errors=\"ignore\", inplace=True)\n",
    "    df.to_excel(fname, index=False)\n",
    "    \n",
    "    print(f\"\\nâœ… ä¿å­˜æˆåŠŸï¼š{fname}\")\n",
    "    print(f\"   ðŸ“¦ å…± {len(df)} æ¡ï¼ˆåŽ»é‡åŽï¼‰\")\n",
    "    print(f\"   ðŸ”¢ æ€»è¯·æ±‚æ•°: {request_count} æ¬¡\")\n",
    "    print(f\"   ðŸ“‹ åˆ—: {', '.join(df.columns.tolist())}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # é¦–æ¬¡å»ºè®®åªæŠ“ 20 æ¡æµ‹è¯•ï¼ŒéªŒè¯é€šè¿‡åŽå¯æ”¹ä¸º 50\n",
    "    run(max_collect=20, page_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ed1113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŠ“å–ç¬¬ 1 é¡µ...\n",
      "æ²¡æœ‰æ›´å¤šæ•°æ®äº†\n",
      "ä¿å­˜æˆåŠŸï¼špythonå²—ä½æ•°æ®_20251112_220055.xlsxï¼Œå…± 0 æ¡èŒä½\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "class BossSpiderAPI:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "           Cookieéœ€è¦ç™»å½•åŽåŽ»ç½‘é¡µä¸ŠèŽ·å–\n",
    "        \"\"\"\n",
    "        self.base_url = \"https://www.zhipin.com/wapi/zpgeek/pc/recommend/job/list.json\"\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36\",\n",
    "            \"Referer\": \"https://www.zhipin.com/\",\n",
    "            \"Cookie\": \"ab_guid=78d319c7-13e6-4a47-baf0-f120a7373d6f; lastCity=100010000; __zp_stoken__=5a4ffw48qw5YKPhRQC2QIF1N3SldZQGZqZlRLXW1WQFjCv2bCkMKiWsKvw4fCrsKRwrbCm8KqwoBmwqPCo8Ozw4TCnUzCrF7Cg8K3wq7CnMKTxJzDrMKFw4tgwpXCvcKmMjUCDQ0NAnF%2Bfn5xCRYDAwwUCwsLFA0CAgINPynDvcKgwpo9M0Y9IEtUVA9UWlpNWkAAUExOMj4CAAENPjc9PTIyw4XCoMKxw6%2FCusKgwrHDoMK6wq%2FCscOgPToyPcKyw7gvRkoBwrISDggBdw7CssOwAcONZS7CrTfCsEo2MzPCvcSzOTIfRz09RDIyOj0yLzIkw4JaIcKtKMK%2FwqQiPR1FMjI7Pz0yMjk9Oy4yRcKGIzI9LTkVAgoDCCxHwrHCgcKyw6cyMg%3D%3D\"\n",
    "        }\n",
    "        self.detail_headers = {\n",
    "            \"User-Agent\": self.headers[\"User-Agent\"],\n",
    "            \"Cookie\": self.headers[\"Cookie\"]\n",
    "        }\n",
    "        self.params = {\n",
    "    \"scene\": \"1\",\n",
    "    \"query\": \"é‡‘èž\",\n",
    "    \"city\": \"100000000\",\n",
    "    \"page\": 1,\n",
    "    \"pageSize\": 30\n",
    "        }\n",
    "\n",
    "        self.data_list = []\n",
    "\n",
    "    def fetch_data(self, max_pages=3):\n",
    "        for page in range(1, max_pages + 1):\n",
    "            print(f\"æŠ“å–ç¬¬ {page} é¡µ...\")\n",
    "            self.params['page'] = page\n",
    "            try:\n",
    "                resp = requests.get(self.base_url, headers=self.headers, params=self.params)\n",
    "                resp.raise_for_status()\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"è¯·æ±‚å¤±è´¥ï¼š{e}\")\n",
    "                continue\n",
    "\n",
    "            result = resp.json()\n",
    "            job_list = result.get(\"zpData\", {}).get(\"jobList\", [])\n",
    "            if not job_list:\n",
    "                print(\"æ²¡æœ‰æ›´å¤šæ•°æ®äº†\")\n",
    "                break\n",
    "\n",
    "            for job in job_list:\n",
    "                job_id = job.get(\"encryptJobId\")\n",
    "                job_desc = self.get_job_detail(job_id)\n",
    "\n",
    "                item = {\n",
    "                    \"èŒä½\": job.get(\"jobName\"),\n",
    "                    \"å…¬å¸\": job.get(\"brandName\"),\n",
    "                    \"è–ªèµ„\": job.get(\"salaryDesc\"),\n",
    "                    \"åœ°åŒº\": job.get(\"cityName\"),\n",
    "                    \"ç»éªŒ\": job.get(\"jobExperience\"),\n",
    "                    \"å­¦åŽ†\": job.get(\"jobDegree\"),\n",
    "                    \"å…¬å¸è§„æ¨¡\": job.get(\"brandScaleName\"),\n",
    "                    \"è¡Œä¸š\": job.get(\"brandIndustry\"),\n",
    "                    \"ç¦åˆ©æ ‡ç­¾\": \",\".join(job.get(\"welfareList\", [])),\n",
    "                    \"æŠ€èƒ½æ ‡ç­¾\": \",\".join(job.get(\"skills\", [])),\n",
    "                    \"èŒä½æè¿°\": job_desc\n",
    "                }\n",
    "                self.data_list.append(item)\n",
    "                time.sleep(random.uniform(1, 1.5))\n",
    "\n",
    "    def get_job_detail(self, job_id):\n",
    "        url = f\"https://www.zhipin.com/job_detail/{job_id}.html\"\n",
    "        try:\n",
    "            resp = requests.get(url, headers=self.detail_headers)\n",
    "            if resp.status_code != 200:\n",
    "                return \"\"\n",
    "            soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "            desc_tag = soup.select_one('.job-sec-text')\n",
    "            return desc_tag.text.strip() if desc_tag else \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"è¯¦æƒ…é¡µèŽ·å–å¤±è´¥: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def save_excel(self):\n",
    "        filename = f\"pythonå²—ä½æ•°æ®_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "        df = pd.DataFrame(self.data_list)\n",
    "        df.to_excel(filename, index=False)\n",
    "        print(f\"ä¿å­˜æˆåŠŸï¼š{filename}ï¼Œå…± {len(df)} æ¡èŒä½\")\n",
    "\n",
    "    def run(self):\n",
    "        self.fetch_data()\n",
    "        self.save_excel()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spider = BossSpiderAPI()\n",
    "    spider.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ å¼€å§‹æŠ“å–é‡‘èžè¡Œä¸šèŒä½...\n",
      "\n",
      "============================================================\n",
      "å…³é”®è¯: é‡‘èž\n",
      "============================================================\n",
      "\n",
      "ðŸ” æŠ“å–å…³é”®è¯ [é‡‘èž] ç¬¬ 1 é¡µ...\n",
      "âœ… èŽ·å–åˆ° 30 ä¸ªèŒä½\n",
      "  ðŸ’¼ [1] å®žä¹ ç”Ÿï¼ˆ25å±Š+é‡‘èžå­¦ä¼˜å…ˆï¼‰ - æ±Ÿè‹å¤©é¼Ž\n",
      "  ðŸ’¼ [2] å­¦ç§‘ç¼–è¾‘ï¼ˆé‡‘èžå­¦ã€ç»æµŽå­¦æ–¹å‘ï¼‰ - æ™ºæ…§æ ‘\n",
      "  ðŸ’¼ [3] è¯šè˜é‡‘èžä¸šå‚¨å¤‡ç®¡ç†+ å¿«é€Ÿæ™‹å‡+é«˜è–ª2w+ï¼ - å°ä¼åŠ©åŠ›\n",
      "  ðŸ’¼ [4] æ¡ˆå‰å¤–è”è°ƒè§£å‘˜-é‡‘èžä¸š - é‚¯éƒ¸å¾‹æ•°\n",
      "  ðŸ’¼ [5] é‡‘èžç±»  æ•°æ®æ ‡æ³¨ - å››å·çŸ¥æ¾³æ•°æ®ç§‘æŠ€\n",
      "  ðŸ’¼ [6] é‡‘èžç±»å‚¨å¤‡å¹²éƒ¨ï¼ˆæ¶‰å¤–æ–¹å‘ï¼‰ - åŽå‹é’´ä¸š\n",
      "  ðŸ’¼ [7] é‡‘èžä¸šè§„åˆ’é¡¾é—®+æ–°äºº1W+å…¥èŒæœ‰äº”é™©ä¸€é‡‘åŒä¼‘ - çŽ–æ©¡å’¨è¯¢\n",
      "  ðŸ’¼ [8] ç½‘æ ¼å‘˜ï¼‹äº”é™©ä¸€é‡‘ï¼‹é‡‘èžä¸šï¼‹å‘¨æœ«åŒä¼‘ - è‘«èŠ¦å²›å¸‚å¤©æ¶¦ç§‘æŠ€\n",
      "  ðŸ’¼ [9] é‡‘èžç±»æ ‡æ³¨-ä¸Šå¸‚å¤–ä¼-å…­é™©ä¸€é‡‘ - æ¾³é¹ç§‘æŠ€\n",
      "  ðŸ’¼ [10] é‡‘èžä¸šåˆä¼™äºº - æ¹–åŒ—æ™Ÿé‚¦ä¿¡ç”¨ç®¡ç†\n",
      "  ðŸ’¼ [11] é‡‘èžç±»é¡¹ç›®åŠ©ç† - ä¸­è´¢é›†å›¢\n",
      "  ðŸ’¼ [12] é‡‘èžä¸šæ ‡æ³¨/åŒä¼‘äº”é™©ä¸€é‡‘ - ä¸‡å£°é€šè®¯å®žä¸šæœ‰é™å…¬å¸\n",
      "  ðŸ’¼ [13] çŸ­è§†é¢‘ç¼–å¯¼ï¼ˆé‡‘èžä¸šï¼‰ - å“†å•¦æœä¿\n",
      "  ðŸ’¼ [14] è´¢ç»é‡‘èžç±»è®°è€… - æ²ˆé˜³æ©™æžœæ–‡åŒ–ä¼ åª’\n",
      "  ðŸ’¼ [15] ç§˜ä¹¦é‡‘èžç±» - é“­é¼Žä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 213\u001b[39m\n\u001b[32m    210\u001b[39m keywords = [\u001b[33m\"\u001b[39m\u001b[33mé‡‘èž\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mé“¶è¡Œ\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mè¯åˆ¸\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33måŸºé‡‘\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mä¿é™©\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# æ¯ä¸ªå…³é”®è¯æŠ“å– 3 é¡µï¼ˆå»ºè®®é¦–æ¬¡æµ‹è¯•ç”¨ 1-2 é¡µï¼‰\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[43mspider\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pages_per_kw\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# å…ˆç”¨å‰2ä¸ªå…³é”®è¯æµ‹è¯•\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 198\u001b[39m, in \u001b[36mBossSpiderAPI.run\u001b[39m\u001b[34m(self, keywords, max_pages_per_kw)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33må…³é”®è¯: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyword\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    197\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_pages_per_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# å…³é”®è¯é—´å»¶æ—¶\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keyword != keywords[-\u001b[32m1\u001b[39m]:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 129\u001b[39m, in \u001b[36mBossSpiderAPI.fetch_data\u001b[39m\u001b[34m(self, query, max_pages)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ðŸ’¼ [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinance_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrand_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# èŽ·å–èŒä½è¯¦æƒ…\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m job_desc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_job_detail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# æž„å»ºæ•°æ®é¡¹\u001b[39;00m\n\u001b[32m    132\u001b[39m item = {\n\u001b[32m    133\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mèŒä½\u001b[39m\u001b[33m\"\u001b[39m: job_name,\n\u001b[32m    134\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33må…¬å¸\u001b[39m\u001b[33m\"\u001b[39m: brand_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mèŒä½æè¿°\u001b[39m\u001b[33m\"\u001b[39m: job_desc\n\u001b[32m    144\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 161\u001b[39m, in \u001b[36mBossSpiderAPI.get_job_detail\u001b[39m\u001b[34m(self, job_id)\u001b[39m\n\u001b[32m    159\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://www.zhipin.com/job_detail/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     resp = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetail_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resp.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m    163\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xixif\\miniconda3\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "class BossSpiderAPI:\n",
    "    def __init__(self):\n",
    "        \"\"\"é‡‘èžè¡Œä¸šèŒä½çˆ¬è™«\"\"\"\n",
    "        # ä½¿ç”¨æœç´¢æŽ¥å£\n",
    "        self.base_url = \"https://www.zhipin.com/wapi/zpgeek/search/joblist.json\"\n",
    "        \n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36\",\n",
    "            \"Referer\": \"https://www.zhipin.com/web/geek/job\",\n",
    "            \"Accept\": \"application/json, text/plain, */*\",\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "            \"Cookie\": \"ab_guid=78d319c7-13e6-4a47-baf0-f120a7373d6f; lastCity=100010000; __zp_stoken__=5a4ffw48LxIYLOBVRCWUOfcKFFkhJSHFuTUvCvGF6wrJgaMKwwrzCssK7wqzCtGzCoFbCgsK0worCucOFZsKZdMKvwq%2FCmFPCpcKTw7PCk8KMU8KSxJrDrcKExLHDuMKjwrzCpzA0FAwMDwPCh39%2FfHAPFwIBDQIKCgkVCwMDAAw5KMO8wqLCmzsyRz8hTVVVDVVcW0xYQRZRTUwzOAMBAww4Njw%2FM0TDhMKhwrPDrsK8wqHCsMOiwrvCqcKww6E%2FO0Q8wrPDui4wSwDCsBMICQB1D8OEw7EAw49kKMK0wq7CsiYgMjLCv8SyPzMeRTw7RTMwOzszLjAYw5RbIMK3wqHCuWkjPxwzMzM5PjszMzs8PS8zRzg1MzwvOAMDCwEJKkbCsMKDwrPDkTMz\"\n",
    "        }\n",
    "        \n",
    "        self.detail_headers = {\n",
    "            \"User-Agent\": self.headers[\"User-Agent\"],\n",
    "            \"Cookie\": self.headers[\"Cookie\"]\n",
    "        }\n",
    "        \n",
    "        # é‡‘èžç›¸å…³å…³é”®è¯ï¼ˆç”¨äºŽäºŒæ¬¡è¿‡æ»¤ï¼‰\n",
    "        self.finance_pattern = re.compile(\n",
    "            r\"(é‡‘èž|é“¶è¡Œ|åˆ¸å•†|è¯åˆ¸|åŸºé‡‘|ä¿é™©|æœŸè´§|ä¿¡æ‰˜|æŠ•è¡Œ|èµ„ç®¡|ç†è´¢|è´¢å¯Œ|\"\n",
    "            r\"å°è´·|æ¶ˆé‡‘|ä¿ç†|ç§Ÿèµ|å¾ä¿¡|æ¸…ç®—|æ”¯ä»˜|äº’é‡‘|é‡‘èžç§‘æŠ€|FinTech)\",\n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.seen_ids = set()  # åŽ»é‡\n",
    "\n",
    "    def is_finance_related(self, job):\n",
    "        \"\"\"åˆ¤æ–­æ˜¯å¦ä¸ºé‡‘èžç›¸å…³èŒä½\"\"\"\n",
    "        text = \" \".join([\n",
    "            job.get(\"brandIndustry\", \"\") or \"\",\n",
    "            job.get(\"brandName\", \"\") or \"\",\n",
    "            job.get(\"jobName\", \"\") or \"\"\n",
    "        ])\n",
    "        return bool(self.finance_pattern.search(text))\n",
    "\n",
    "    def fetch_data(self, query=\"é‡‘èž\", max_pages=5):\n",
    "        \"\"\"\n",
    "        æŠ“å–èŒä½æ•°æ®\n",
    "        \n",
    "        å‚æ•°:\n",
    "            query: æœç´¢å…³é”®è¯ï¼ˆå¯ä»¥æ˜¯\"é‡‘èž\"ã€\"é“¶è¡Œ\"ç­‰ï¼‰\n",
    "            max_pages: æœ€å¤§æŠ“å–é¡µæ•°\n",
    "        \"\"\"\n",
    "        for page in range(1, max_pages + 1):\n",
    "            print(f\"\\nðŸ” æŠ“å–å…³é”®è¯ [{query}] ç¬¬ {page} é¡µ...\")\n",
    "            \n",
    "            # æž„å»ºè¯·æ±‚å‚æ•°\n",
    "            params = {\n",
    "                \"scene\": \"1\",\n",
    "                \"query\": query,\n",
    "                \"city\": \"100010000\",  # 100010000=åŒ—äº¬, 100000000=å…¨å›½\n",
    "                \"page\": page,\n",
    "                \"pageSize\": 30\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                # ä½¿ç”¨ POST æ–¹æ³•ï¼Œå‚æ•°æ”¾åœ¨ data ä¸­\n",
    "                resp = requests.post(\n",
    "                    self.base_url, \n",
    "                    headers=self.headers, \n",
    "                    data=params,\n",
    "                    timeout=15\n",
    "                )\n",
    "                resp.raise_for_status()\n",
    "                \n",
    "            except requests.RequestException as e:\n",
    "                print(f\"âŒ è¯·æ±‚å¤±è´¥ï¼š{e}\")\n",
    "                continue\n",
    "\n",
    "            # è§£æžå“åº”\n",
    "            try:\n",
    "                result = resp.json()\n",
    "                \n",
    "                # æ£€æŸ¥è¿”å›žç \n",
    "                code = result.get(\"code\")\n",
    "                msg = result.get(\"message\") or result.get(\"msg\")\n",
    "                \n",
    "                if code == 37:\n",
    "                    print(f\"âš ï¸ è§¦å‘é£ŽæŽ§ (code: 37)ï¼Œè¯·æ›´æ–° Cookieï¼\")\n",
    "                    break\n",
    "                elif code not in (0, \"0\", None):\n",
    "                    print(f\"âš ï¸ æŽ¥å£å¼‚å¸¸ code: {code}, message: {msg}\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è§£æžå“åº”å¤±è´¥: {e}\")\n",
    "                print(f\"å“åº”å†…å®¹: {resp.text[:300]}\")\n",
    "                continue\n",
    "\n",
    "            # èŽ·å–èŒä½åˆ—è¡¨\n",
    "            job_list = result.get(\"zpData\", {}).get(\"jobList\", [])\n",
    "            \n",
    "            if not job_list:\n",
    "                print(\"âš ï¸ æœ¬é¡µæ— æ•°æ®ï¼Œç»“æŸæŠ“å–\")\n",
    "                break\n",
    "            \n",
    "            print(f\"âœ… èŽ·å–åˆ° {len(job_list)} ä¸ªèŒä½\")\n",
    "            \n",
    "            # å¤„ç†æ¯ä¸ªèŒä½\n",
    "            finance_count = 0\n",
    "            for job in job_list:\n",
    "                job_id = job.get(\"encryptJobId\")\n",
    "                \n",
    "                # åŽ»é‡\n",
    "                if not job_id or job_id in self.seen_ids:\n",
    "                    continue\n",
    "                \n",
    "                # é‡‘èžè¡Œä¸šè¿‡æ»¤\n",
    "                if not self.is_finance_related(job):\n",
    "                    continue\n",
    "                \n",
    "                finance_count += 1\n",
    "                brand_name = job.get(\"brandName\")\n",
    "                job_name = job.get(\"jobName\")\n",
    "                print(f\"  ðŸ’¼ [{finance_count}] {job_name} - {brand_name}\")\n",
    "                \n",
    "                # èŽ·å–èŒä½è¯¦æƒ…\n",
    "                job_desc = self.get_job_detail(job_id)\n",
    "                \n",
    "                # æž„å»ºæ•°æ®é¡¹\n",
    "                item = {\n",
    "                    \"èŒä½\": job_name,\n",
    "                    \"å…¬å¸\": brand_name,\n",
    "                    \"è–ªèµ„\": job.get(\"salaryDesc\"),\n",
    "                    \"åœ°åŒº\": job.get(\"cityName\"),\n",
    "                    \"ç»éªŒ\": job.get(\"jobExperience\"),\n",
    "                    \"å­¦åŽ†\": job.get(\"jobDegree\"),\n",
    "                    \"å…¬å¸è§„æ¨¡\": job.get(\"brandScaleName\"),\n",
    "                    \"è¡Œä¸š\": job.get(\"brandIndustry\"),\n",
    "                    \"ç¦åˆ©æ ‡ç­¾\": \",\".join(job.get(\"welfareList\", []) or []),\n",
    "                    \"æŠ€èƒ½æ ‡ç­¾\": \",\".join(job.get(\"skills\", []) or []),\n",
    "                    \"èŒä½æè¿°\": job_desc\n",
    "                }\n",
    "                \n",
    "                self.data_list.append(item)\n",
    "                self.seen_ids.add(job_id)\n",
    "                \n",
    "                # éšæœºå»¶æ—¶ï¼Œé¿å…è¢«å°\n",
    "                time.sleep(random.uniform(1.5, 2.5))\n",
    "            \n",
    "            print(f\"ðŸ“Š æœ¬é¡µç¬¦åˆæ¡ä»¶: {finance_count} ä¸ª | ç´¯è®¡: {len(self.data_list)} ä¸ª\")\n",
    "            \n",
    "            # æ¯é¡µä¹‹é—´å»¶æ—¶\n",
    "            time.sleep(random.uniform(2.0, 3.0))\n",
    "\n",
    "    def get_job_detail(self, job_id):\n",
    "        \"\"\"èŽ·å–èŒä½è¯¦æƒ…æè¿°\"\"\"\n",
    "        url = f\"https://www.zhipin.com/job_detail/{job_id}.html\"\n",
    "        try:\n",
    "            resp = requests.get(url, headers=self.detail_headers, timeout=10)\n",
    "            if resp.status_code != 200:\n",
    "                return \"\"\n",
    "            soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "            desc_tag = soup.select_one('.job-sec-text')\n",
    "            return desc_tag.text.strip() if desc_tag else \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ è¯¦æƒ…é¡µèŽ·å–å¤±è´¥: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def save_excel(self):\n",
    "        \"\"\"ä¿å­˜ä¸º Excel æ–‡ä»¶\"\"\"\n",
    "        if not self.data_list:\n",
    "            print(\"\\nâŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜\")\n",
    "            return\n",
    "        \n",
    "        filename = f\"é‡‘èžè¡Œä¸šå²—ä½_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "        df = pd.DataFrame(self.data_list)\n",
    "        df.to_excel(filename, index=False)\n",
    "        print(f\"\\nâœ… ä¿å­˜æˆåŠŸï¼š{filename}\")\n",
    "        print(f\"   ðŸ“¦ å…± {len(df)} æ¡èŒä½\")\n",
    "        print(f\"   ðŸ“‹ åŒ…å«åˆ—: {', '.join(df.columns.tolist())}\")\n",
    "\n",
    "    def run(self, keywords=[\"é‡‘èž\"], max_pages_per_kw=3):\n",
    "        \"\"\"\n",
    "        è¿è¡Œçˆ¬è™«\n",
    "        \n",
    "        å‚æ•°:\n",
    "            keywords: å…³é”®è¯åˆ—è¡¨ï¼Œå¦‚ [\"é‡‘èž\", \"é“¶è¡Œ\", \"è¯åˆ¸\"]\n",
    "            max_pages_per_kw: æ¯ä¸ªå…³é”®è¯æŠ“å–çš„æœ€å¤§é¡µæ•°\n",
    "        \"\"\"\n",
    "        print(\"ðŸš€ å¼€å§‹æŠ“å–é‡‘èžè¡Œä¸šèŒä½...\")\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"å…³é”®è¯: {keyword}\")\n",
    "            print('='*60)\n",
    "            self.fetch_data(query=keyword, max_pages=max_pages_per_kw)\n",
    "            \n",
    "            # å…³é”®è¯é—´å»¶æ—¶\n",
    "            if keyword != keywords[-1]:\n",
    "                time.sleep(random.uniform(3.0, 5.0))\n",
    "        \n",
    "        self.save_excel()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spider = BossSpiderAPI()\n",
    "    \n",
    "    # å¯ä»¥æœç´¢å¤šä¸ªå…³é”®è¯\n",
    "    keywords = [\"é‡‘èž\", \"é“¶è¡Œ\", \"è¯åˆ¸\", \"åŸºé‡‘\", \"ä¿é™©\"]\n",
    "    \n",
    "    # æ¯ä¸ªå…³é”®è¯æŠ“å– 3 é¡µï¼ˆå»ºè®®é¦–æ¬¡æµ‹è¯•ç”¨ 1-2 é¡µï¼‰\n",
    "    spider.run(keywords=keywords[:2], max_pages_per_kw=2)  # å…ˆç”¨å‰2ä¸ªå…³é”®è¯æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f54031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ (é˜¶æ®µ1) å¼€å§‹æŠ“å–èŒä½åˆ—è¡¨...\n",
      "\n",
      "============================================================\n",
      "å…³é”®è¯: é‡‘èž\n",
      "============================================================\n",
      "\n",
      "ðŸ” æŠ“å–å…³é”®è¯ [é‡‘èž] åˆ—è¡¨ç¬¬ 1 é¡µ...\n",
      "âœ… èŽ·å–åˆ° 30 ä¸ªèŒä½\n",
      "ðŸ“Š æœ¬é¡µç¬¦åˆæ¡ä»¶: 30 ä¸ª | ç´¯è®¡: 30 ä¸ª\n",
      "\n",
      "ðŸ” æŠ“å–å…³é”®è¯ [é‡‘èž] åˆ—è¡¨ç¬¬ 2 é¡µ...\n",
      "âœ… èŽ·å–åˆ° 30 ä¸ªèŒä½\n",
      "ðŸ“Š æœ¬é¡µç¬¦åˆæ¡ä»¶: 11 ä¸ª | ç´¯è®¡: 41 ä¸ª\n",
      "\n",
      "============================================================\n",
      "å…³é”®è¯: é“¶è¡Œ\n",
      "============================================================\n",
      "\n",
      "ðŸ” æŠ“å–å…³é”®è¯ [é“¶è¡Œ] åˆ—è¡¨ç¬¬ 1 é¡µ...\n",
      "âœ… èŽ·å–åˆ° 30 ä¸ªèŒä½\n",
      "ðŸ“Š æœ¬é¡µç¬¦åˆæ¡ä»¶: 27 ä¸ª | ç´¯è®¡: 68 ä¸ª\n",
      "\n",
      "ðŸ” æŠ“å–å…³é”®è¯ [é“¶è¡Œ] åˆ—è¡¨ç¬¬ 2 é¡µ...\n",
      "âš ï¸ è§¦å‘é£ŽæŽ§ (code: 37)ï¼Œè¯·æ›´æ–° Cookieï¼\n",
      "\n",
      "ðŸ‘ (é˜¶æ®µ1) èŒä½åˆ—è¡¨æŠ“å–å®Œæ¯•ã€‚\n",
      "\n",
      "============================================================\n",
      "ðŸš€ å¼€å§‹æŠ“å– 68 ä¸ªèŒä½çš„è¯¦ç»†æè¿°...\n",
      "   (æ­¤è¿‡ç¨‹è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…)\n",
      "============================================================\n",
      "  (1/68) æŠ“å–: å®žä¹ ç”Ÿï¼ˆ25å±Š+é‡‘èžå­¦ä¼˜å…ˆï¼‰ - æ±Ÿè‹å¤©é¼Ž\n",
      "  (2/68) æŠ“å–: å­¦ç§‘ç¼–è¾‘ï¼ˆé‡‘èžå­¦ã€ç»æµŽå­¦æ–¹å‘ï¼‰ - æ™ºæ…§æ ‘\n",
      "  (3/68) æŠ“å–: è¯šè˜é‡‘èžä¸šå‚¨å¤‡ç®¡ç†+ å¿«é€Ÿæ™‹å‡+é«˜è–ª2w+ï¼ - å°ä¼åŠ©åŠ›\n",
      "  (4/68) æŠ“å–: æ¡ˆå‰å¤–è”è°ƒè§£å‘˜-é‡‘èžä¸š - é‚¯éƒ¸å¾‹æ•°\n",
      "  (5/68) æŠ“å–: é‡‘èžç±»  æ•°æ®æ ‡æ³¨ - å››å·çŸ¥æ¾³æ•°æ®ç§‘æŠ€\n",
      "  (6/68) æŠ“å–: é‡‘èžç±»å‚¨å¤‡å¹²éƒ¨ï¼ˆæ¶‰å¤–æ–¹å‘ï¼‰ - åŽå‹é’´ä¸š\n",
      "  (7/68) æŠ“å–: é‡‘èžä¸šè§„åˆ’é¡¾é—®+æ–°äºº1W+å…¥èŒæœ‰äº”é™©ä¸€é‡‘åŒä¼‘ - çŽ–æ©¡å’¨è¯¢\n",
      "  (8/68) æŠ“å–: ç½‘æ ¼å‘˜ï¼‹äº”é™©ä¸€é‡‘ï¼‹é‡‘èžä¸šï¼‹å‘¨æœ«åŒä¼‘ - è‘«èŠ¦å²›å¸‚å¤©æ¶¦ç§‘æŠ€\n",
      "  (9/68) æŠ“å–: é‡‘èžç±»æ ‡æ³¨-ä¸Šå¸‚å¤–ä¼-å…­é™©ä¸€é‡‘ - æ¾³é¹ç§‘æŠ€\n",
      "  (10/68) æŠ“å–: é‡‘èžä¸šåˆä¼™äºº - æ¹–åŒ—æ™Ÿé‚¦ä¿¡ç”¨ç®¡ç†\n",
      "  (11/68) æŠ“å–: é‡‘èžç±»é¡¹ç›®åŠ©ç† - ä¸­è´¢é›†å›¢\n",
      "  (12/68) æŠ“å–: é‡‘èžä¸šæ ‡æ³¨/åŒä¼‘äº”é™©ä¸€é‡‘ - ä¸‡å£°é€šè®¯å®žä¸šæœ‰é™å…¬å¸\n",
      "  (13/68) æŠ“å–: çŸ­è§†é¢‘ç¼–å¯¼ï¼ˆé‡‘èžä¸šï¼‰ - å“†å•¦æœä¿\n",
      "  (14/68) æŠ“å–: è´¢ç»é‡‘èžç±»è®°è€… - æ²ˆé˜³æ©™æžœæ–‡åŒ–ä¼ åª’\n",
      "  (15/68) æŠ“å–: ç§˜ä¹¦é‡‘èžç±» - é“­é¼Žä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n",
      "  (16/68) æŠ“å–: é«˜è–ªæ‹›è˜è‹±æ–‡é‡‘èžç±»è®²è§£å‘˜ - æ³°ç›ˆç§‘æŠ€é›†å›¢\n",
      "  (17/68) æŠ“å–: æ³›å•†ä¸šã€é‡‘èžç±»æ–°åª’ä½“è¿è¥ - å±±ä¸œä¸–è£•\n",
      "  (18/68) æŠ“å–: å®¢æˆ·é‚€çº¦ä¸“å‘˜ï¼ˆé‡‘èžç±»ï¼‰ - å±±ä¸œæ²è¿œä¼ä¸šå’¨è¯¢æœåŠ¡\n",
      "  (19/68) æŠ“å–: ç»ç®¡é‡‘èžç±»è®ºæ–‡è¾…å¯¼å¯¼å¸ˆï¼ˆå…¼èŒï¼‰ - é˜³æ–°å®‰æ­£ç½‘ç»œç§‘æŠ€...\n",
      "  (20/68) æŠ“å–: è´¢å¯Œè§„åˆ’å¸ˆï¼ˆé‡‘èžç±»é”€å”®ï¼‰ - å›½è”è¯åˆ¸ä¸¹é˜³è¥ä¸šéƒ¨\n",
      "  (21/68) æŠ“å–: å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼ˆé‡‘èžç±»ï¼‰ - å®‰å¾½å…†å°¹ç§‘æŠ€\n",
      "  (22/68) æŠ“å–: æ•°å­¦ã€é‡‘èžç±»è‹±æ–‡å­¦æœ¯æœŸåˆŠåŠ©ç†ç¼–è¾‘ - æ›¼è¿ªåŒ¹è‰¾\n",
      "  (23/68) æŠ“å–: åŽç«¯å¼€å‘-é‡‘èžç±»é¡¹ç›®/å­¦ä¿¡ç½‘ - åšå½¦ç§‘æŠ€\n",
      "  (24/68) æŠ“å–: é‡‘èžç±»å…¼èŒç¿»è¯‘-è‹±è¯‘ä¸­ - SDL PLC\n",
      "  (25/68) æŠ“å–: è…¾è®¯å¹¿ç‚¹é€šä¼˜åŒ–å¸ˆï¼ˆé‡‘èžç±»ï¼‰ - å¼€åŸŸé›†å›¢\n",
      "  (26/68) æŠ“å–: javaå¼€å‘å·¥ç¨‹å¸ˆï¼ˆé“¶è¡Œé‡‘èžç±»ï¼‰ - ç¥žå·žä¿¡æ¯\n",
      "  (27/68) æŠ“å–: é‡‘èžç±»ç”µè¯åå¸­ - ä¸­è£ç‘žè¾¾\n",
      "  (28/68) æŠ“å–: è¯‰å‰è°ƒè§£ï¼ˆé‡‘èžç±»ç³»åˆ—æ¡ˆï¼‰ - å­¦ä¼˜å¾‹æ‰€\n",
      "  (29/68) æŠ“å–: å¤§å®¢æˆ·é”€å”®ç»ç†ï¼ˆé‡‘èžç±»-åŽåŒ—ï¼‰ - æµ·è‡´æ˜Ÿå›¾\n",
      "  (30/68) æŠ“å–: é‡‘èžç±»é”€å”®  ä¸åŠ ç­  äº¤äº”é™© - åˆè‚¥æ˜“ä»£é€šä¿¡æ¯ç§‘æŠ€\n",
      "  (31/68) æŠ“å–: ã€å…¼èŒã€‘é‡‘èžç±»æ–‡æ¡ˆç­–åˆ’ - æŠ–åŠ¨è§†ç•Œæ–‡åŒ–ä¼ æ’­å…¬å¸\n",
      "  (32/68) æŠ“å–: é‡‘èžç±»å’¨è¯¢å®¢æœ  æ— é”€å”® äº”é™©ä¸€é‡‘+ä½å®¿ - å—é€šå…‰ç‘¾ä¸°\n",
      "  (33/68) æŠ“å–: äº’è”ç½‘é‡‘èžç±»å›žæ¬¾ä¸“å‘˜ - è”ä¿¡é›†å›¢\n",
      "  (34/68) æŠ“å–: çŸ­è§†é¢‘å‰ªè¾‘ï¼ˆé‡‘èžç±»+åŒä¼‘+äº”é™©ä¸€é‡‘ï¼‰ - å·¨ä¸°æŠ•é¡¾\n",
      "  (35/68) æŠ“å–: åŒä¼‘äº”é™©çƒ­çº¿å®¢æœ-é‡‘èžç±» - æ²³åŒ—èµ›è¯º\n",
      "  (36/68) æŠ“å–: æ­¦æ±‰-javaç ”å‘å·¥ç¨‹å¸ˆ(é‡‘èžç±»ä¸šåŠ¡) - é¡ºä¸°ç§‘æŠ€\n",
      "  (37/68) æŠ“å–: ä¸‡è¾¾åŒä¼‘é”€å”®  éžä¸€ç³»åˆ—é‡‘èžç±» - æ±Ÿè‹é•¿å†¶\n",
      "  (38/68) æŠ“å–: é“¶è¡Œé‡‘èžä¸šæ•°æ®ä»“åº“å®žæ–½ - åŒ—äº¬å¤æ‰\n",
      "  (39/68) æŠ“å–: Tech Lead,Digital,Global Financial Mkts - æ˜Ÿå±•ç§‘æŠ€\n",
      "  (40/68) æŠ“å–: Financial Analyst - å®åˆ©é‡‘èžå…¨çƒæœåŠ¡ä¸­å¿ƒ\n",
      "  (41/68) æŠ“å–: åŒºåŸŸæ‹›å•†ç»ç†ï¼ˆæˆ¿åœ°äº§é‡‘èžç±»è¡Œä¸šç»éªŒè€ƒè™‘ï¼‰ - æ±Ÿè‹å¹¿æ‰¿\n",
      "  (42/68) æŠ“å–: é“¶è¡ŒèŒå‘˜(æ­¦æ±‰åˆ†è¡Œ  ä»…æ‹›2åï¼‰ - ä¸­ä¿¡é“¶è¡Œ\n",
      "  (43/68) æŠ“å–: Bank Debt Collection Officer(ç²¤è¯­ï¼†è‹±è¯­) - æ·±åœ³å¸‚æ’é“¶ç§‘æŠ€æœåŠ¡\n",
      "  (44/68) æŠ“å–: æ”¶å•ä¸šåŠ¡æ‹“å±•å²— - è¿žé€šæŠ€æœ¯\n",
      "  (45/68) æŠ“å–: Android Developer (ç›´æ‹›éžå¤–åŒ…ï¼‰ - æ¸£æ‰“çŽ¯çƒæœåŠ¡ä¸­å¿ƒ\n",
      "  (46/68) æŠ“å–: AI Full Stack Product Developer å…¨æ ˆå¼€å‘ - æ¸£æ‰“çŽ¯çƒå¹¿å·žæœåŠ¡ä¸­å¿ƒ\n",
      "  (47/68) æŠ“å–: ä¿¡ç”¨å¡é”€å”®ä¸“å‘˜ - ç„¦ä½œå¸‚é“åˆåŒåˆ›ä¿¡...\n",
      "  (48/68) æŠ“å–: ã€åç­ç¨³å®šå®¢æœå²—ä½ã€‘åº•è–ª6000 åˆ°ç‚¹å³èµ° - ä¸Šè´¾å•†åŠ¡\n",
      "  (49/68) æŠ“å–: æ–°äºº26000+ä½å®¿ï¼ˆå…è´¹ï¼‰äº”é™©ä¸€é‡‘+50%ææˆ - å®‰å®‰æ™®æƒ \n",
      "  (50/68) æŠ“å–: ä¹é¾™å¡åŒä¼‘ç¤¾åŒºé‡‘èžæœåŠ¡ä¸“å‘˜ - ä¸­å›½å¹³å®‰é“¶è¡Œ\n",
      "  (51/68) æŠ“å–: ç½‘ç»œå®¢æœä¸“å‘˜ - é¡ºæ˜“\n",
      "  (52/68) æŠ“å–: é“¶è¡Œå¤§å ‚åŠ©ç†ï¼ˆå°±è¿‘åˆ†é…ï¼‰ - æ‹›å•†é“¶è¡Œä¿¡ç”¨å¡ä¸­å¿ƒ\n",
      "  (53/68) æŠ“å–: æ»¡16å²åŒå­¦å³å¯å…¥èŒï¼ˆå¯å¸¦æœ‹å‹è½»æ¾æ··åº•è–ªï¼‰ - è‹å·žåŽé“æ•°æ®å¤„ç†\n",
      "  (54/68) æŠ“å–: è‡ªè¥å†…å‚¬  äº”é™©ä¸€é‡‘  å…¥èŒä¿åº•5700+ - è¿ªç§‘æ•°é‡‘\n",
      "  (55/68) æŠ“å–: é“¶è¡Œä¿¡æ¯å½•å…¥å‘˜/äº”é™©ä¸€é‡‘/æ— è´£5.5k - æ±‡é¼Ž\n",
      "  (56/68) æŠ“å–: ï¼ˆé¾™æ–‡ï¼‰å›½æœ‰é“¶è¡Œå‚¬æ”¶å‘˜-äº”é™©+å¸¦è–ªå¹´å‡ - é“¶ä¿¡è¾¾\n",
      "  (57/68) æŠ“å–: ä¿¡è´·å®¡æŸ¥å²— - æ³°éš†å•†ä¸šé“¶è¡Œ\n",
      "  (58/68) æŠ“å–: çœŸçš„å¾ˆè¦äººï¼ˆé¢è¯•å°±è¿‡ï¼‰æ—©ä¹æ™šå…­å‘¨æœ«åŒä¼‘ - è¯šè”æ±‡\n",
      "  (59/68) æŠ“å–: åŠžå…¬å®¤æ–‡å‘˜ - é“‚å®¸ç§‘æŠ€å‘å±•æœ‰é™å…¬å¸\n",
      "  (60/68) æŠ“å–: ç”µè¯å®¢æœ - éŸ¶å…³é›†é‘«å’¨è¯¢\n",
      "  (61/68) æŠ“å–: é“¶è¡Œå®¢æœï¼ˆçº¯åç­ï¼Œæ— éœ€å¤–å‡ºï¼ï¼ï¼‰ - æµ©ä¼ ä¼ä¸š\n",
      "  (62/68) æŠ“å–: è¾“å•å‘˜ - è‹æŒ¯è£\n",
      "  (63/68) æŠ“å–: å‚¬æ”¶ç»„é•¿ï¼ˆèš‚èšé¡¹ç›®+é¡¹ç›®ç»ç†æ–¹å‘ï¼‰ - æ·±åœ³é›æ‰¬ç§‘æŠ€æœåŠ¡...\n",
      "  (64/68) æŠ“å–: æ•°æ®å¼€å‘å·¥ç¨‹å¸ˆï¼ˆåˆçº§ï¼‰ - æ‹›å•†æ°¸éš†é“¶è¡Œæ·±åœ³åˆ†è¡Œ\n",
      "  (65/68) æŠ“å–: é‡‘èžæ¸ é“ç»ç† - é‡‘è£•ç‘žå®\n",
      "  (66/68) æŠ“å–: åŒºåŸŸç»ç† - å¹³å®‰ç»¼åˆé‡‘èž\n",
      "  (67/68) æŠ“å–: æ— è´£åº•è–ªå‚¬ æ”¶ å‘˜ - æŸ³å·žä¼—è¯šæ³•å¾‹\n",
      "  (68/68) æŠ“å–: åŠžå…¬å®¤æ–‡å‘˜å²— ä¼šæ²Ÿé€šçš„æ¥ - ä¸Šå–„èµ£å·žåˆ†å…¬å¸\n",
      "\n",
      "âœ… æ‰€æœ‰èŒä½æè¿°æŠ“å–å®Œæ¯•ã€‚\n",
      "\n",
      "âœ… ä¿å­˜æˆåŠŸï¼šé‡‘èžè¡Œä¸šå²—ä½_20251112_233912.xlsx\n",
      "    ðŸ“¦ å…± 68 æ¡èŒä½\n",
      "    ðŸ“‹ åŒ…å«åˆ—: èŒä½, å…¬å¸, è–ªèµ„, åœ°åŒº, ç»éªŒ, å­¦åŽ†, å…¬å¸è§„æ¨¡, è¡Œä¸š, ç¦åˆ©æ ‡ç­¾, æŠ€èƒ½æ ‡ç­¾, èŒä½æè¿°\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "class BossSpiderAPI:\n",
    "    def __init__(self):\n",
    "        \"\"\"é‡‘èžè¡Œä¸šèŒä½çˆ¬è™«\"\"\"\n",
    "        self.base_url = \"https://www.zhipin.com/wapi/zpgeek/search/joblist.json\"\n",
    "        \n",
    "        # ï¼ï¼ï¼æ³¨æ„ï¼šè¿™é‡Œçš„ Cookie å¿…é¡»æ˜¯ä½ åˆšä»Žæµè§ˆå™¨èŽ·å–çš„æœ€æ–°å€¼ï¼ï¼ï¼\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36\",\n",
    "            \"Referer\": \"https://www.zhipin.com/web/geek/job\",\n",
    "            \"Accept\": \"application/json, text/plain, */*\",\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "            # ï¼ï¼ï¼\n",
    "            # ï¼ï¼ï¼æŠŠè¿™é‡Œæ›¿æ¢æˆä½ åˆšF12èŽ·å–çš„æœ€æ–°Cookie\n",
    "            # ï¼ï¼ï¼\n",
    "            \"Cookie\": \"ab_guid=78d319c7-13e6-4a47-baf0-f120a7373d6f; lastCity=100010000; __zp_stoken__=5a4ffw47DpG0IPA1QFGYKDlNoSFVQQFloZE1LUm9USVjCsGTCksKrZV7CpsKwTcOEwqXCq8KuY0lAwr7DhsKiUMKqUsSFwqPCjsK9wpHEnsO1woXErMO8wqbDhMKRPTcAFA0CAHPCh35xcwsPAwwOFgILFBYPCwINDz0gw73Cr8KYPzpGMiJJTVQAVlhTTWVCAllMQTA8CwAODzwuPTIwMMK8wqDCvsOtwrjCqcKxw6%2FCuMKtwrjDoDI4METCssSHLURDAcK9EAwBAWgMwrDDuQHDgmcswpzCrkg0PjrCvcSzOz8mRz0%2FOTsyOj8%2FNjIMw4BnKMKlwqHCsMKbKz0dRz87Oz8%2FPzs5PTkjOzp2IT9ELTkXDwMDCC46wrjCgcKyw6U%2FOw%3D%3D\" \n",
    "        }\n",
    "        \n",
    "        self.detail_headers = {\n",
    "            \"User-Agent\": self.headers[\"User-Agent\"],\n",
    "            \"Cookie\": self.headers[\"Cookie\"]\n",
    "        }\n",
    "        \n",
    "        self.finance_pattern = re.compile(\n",
    "            r\"(é‡‘èž|é“¶è¡Œ|åˆ¸å•†|è¯åˆ¸|åŸºé‡‘|ä¿é™©|æœŸè´§|ä¿¡æ‰˜|æŠ•è¡Œ|èµ„ç®¡|ç†è´¢|è´¢å¯Œ|\"\n",
    "            r\"å°è´·|æ¶ˆé‡‘|ä¿ç†|ç§Ÿèµ|å¾ä¿¡|æ¸…ç®—|æ”¯ä»˜|äº’é‡‘|é‡‘èžç§‘æŠ€|FinTech)\",\n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.seen_ids = set()\n",
    "\n",
    "    def is_finance_related(self, job):\n",
    "        \"\"\"åˆ¤æ–­æ˜¯å¦ä¸ºé‡‘èžç›¸å…³èŒä½\"\"\"\n",
    "        text = \" \".join([\n",
    "            job.get(\"brandIndustry\", \"\") or \"\",\n",
    "            job.get(\"brandName\", \"\") or \"\",\n",
    "            job.get(\"jobName\", \"\") or \"\"\n",
    "        ])\n",
    "        return bool(self.finance_pattern.search(text))\n",
    "\n",
    "    def fetch_data(self, query=\"é‡‘èž\", max_pages=5):\n",
    "        \"\"\"\n",
    "        (ä¿®æ”¹) æŠ“å–èŒä½æ•°æ® - ä»…æŠ“å–åˆ—è¡¨\n",
    "        \"\"\"\n",
    "        for page in range(1, max_pages + 1):\n",
    "            print(f\"\\nðŸ” æŠ“å–å…³é”®è¯ [{query}] åˆ—è¡¨ç¬¬ {page} é¡µ...\")\n",
    "            \n",
    "            params = {\n",
    "                \"scene\": \"1\",\n",
    "                \"query\": query,\n",
    "                \"city\": \"100010000\",\n",
    "                \"page\": page,\n",
    "                \"pageSize\": 30\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                resp = requests.post(\n",
    "                    self.base_url, \n",
    "                    headers=self.headers, \n",
    "                    data=params,\n",
    "                    timeout=15\n",
    "                )\n",
    "                resp.raise_for_status()\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"âŒ è¯·æ±‚å¤±è´¥ï¼š{e}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                result = resp.json()\n",
    "                code = result.get(\"code\")\n",
    "                msg = result.get(\"message\") or result.get(\"msg\")\n",
    "                \n",
    "                if code == 37:\n",
    "                    print(f\"âš ï¸ è§¦å‘é£ŽæŽ§ (code: 37)ï¼Œè¯·æ›´æ–° Cookieï¼\")\n",
    "                    break # åœæ­¢å½“å‰å…³é”®è¯çš„æŠ“å–\n",
    "                elif code not in (0, \"0\", None):\n",
    "                    print(f\"âš ï¸ æŽ¥å£å¼‚å¸¸ code: {code}, message: {msg}\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è§£æžå“åº”å¤±è´¥: {e}\")\n",
    "                print(f\"å“åº”å†…å®¹: {resp.text[:300]}\")\n",
    "                continue\n",
    "\n",
    "            job_list = result.get(\"zpData\", {}).get(\"jobList\", [])\n",
    "            \n",
    "            if not job_list:\n",
    "                print(\"âš ï¸ æœ¬é¡µæ— æ•°æ®ï¼Œç»“æŸæŠ“å–\")\n",
    "                break\n",
    "            \n",
    "            print(f\"âœ… èŽ·å–åˆ° {len(job_list)} ä¸ªèŒä½\")\n",
    "            \n",
    "            finance_count = 0\n",
    "            for job in job_list:\n",
    "                job_id = job.get(\"encryptJobId\")\n",
    "                \n",
    "                if not job_id or job_id in self.seen_ids:\n",
    "                    continue\n",
    "                \n",
    "                if not self.is_finance_related(job):\n",
    "                    continue\n",
    "                \n",
    "                finance_count += 1\n",
    "                \n",
    "                # *** (æ ¸å¿ƒä¿®æ”¹) ***\n",
    "                # å…ˆä¸èŽ·å–è¯¦æƒ…ï¼Œåªä¿å­˜åˆ—è¡¨ä¿¡æ¯\n",
    "                item = {\n",
    "                    \"èŒä½\": job.get(\"jobName\"),\n",
    "                    \"å…¬å¸\": job.get(\"brandName\"),\n",
    "                    \"è–ªèµ„\": job.get(\"salaryDesc\"),\n",
    "                    \"åœ°åŒº\": job.get(\"cityName\"),\n",
    "                    \"ç»éªŒ\": job.get(\"jobExperience\"),\n",
    "                    \"å­¦åŽ†\": job.get(\"jobDegree\"),\n",
    "                    \"å…¬å¸è§„æ¨¡\": job.get(\"brandScaleName\"),\n",
    "                    \"è¡Œä¸š\": job.get(\"brandIndustry\"),\n",
    "                    \"ç¦åˆ©æ ‡ç­¾\": \",\".join(job.get(\"welfareList\", []) or []),\n",
    "                    \"æŠ€èƒ½æ ‡ç­¾\": \",\".join(job.get(\"skills\", []) or []),\n",
    "                    \"èŒä½æè¿°\": \"\",  # æš‚æ—¶ä¸ºç©º\n",
    "                    \"job_id\": job_id # å­˜å‚¨job_idï¼Œä¾›åŽç»­æŠ“å–è¯¦æƒ…\n",
    "                }\n",
    "                \n",
    "                self.data_list.append(item)\n",
    "                self.seen_ids.add(job_id)\n",
    "            \n",
    "            print(f\"ðŸ“Š æœ¬é¡µç¬¦åˆæ¡ä»¶: {finance_count} ä¸ª | ç´¯è®¡: {len(self.data_list)} ä¸ª\")\n",
    "            \n",
    "            # åˆ—è¡¨é¡µä¹‹é—´çš„å»¶æ—¶\n",
    "            time.sleep(random.uniform(2.0, 3.0))\n",
    "\n",
    "    def get_job_detail(self, job_id):\n",
    "        \"\"\"èŽ·å–èŒä½è¯¦æƒ…æè¿°\"\"\"\n",
    "        url = f\"https://www.zhipin.com/job_detail/{job_id}.html\"\n",
    "        try:\n",
    "            resp = requests.get(url, headers=self.detail_headers, timeout=10)\n",
    "            if resp.status_code != 200:\n",
    "                print(f\"  âš ï¸ è¯¦æƒ…é¡µçŠ¶æ€ç : {resp.status_code}\")\n",
    "                # é‡åˆ°403æˆ–404ç­‰ä¹Ÿå¯èƒ½æ„å‘³ç€è¢«é£ŽæŽ§\n",
    "                return \"\"\n",
    "            soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "            desc_tag = soup.select_one('.job-sec-text')\n",
    "            return desc_tag.text.strip() if desc_tag else \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ è¯¦æƒ…é¡µèŽ·å–å¤±è´¥: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    # *** (æ–°å¢žæ–¹æ³•) ***\n",
    "    def fetch_all_details(self):\n",
    "        \"\"\"\n",
    "        åœ¨åˆ—è¡¨æŠ“å–å®Œæ¯•åŽï¼Œç»Ÿä¸€æŠ“å–æ‰€æœ‰è¯¦æƒ…\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ðŸš€ å¼€å§‹æŠ“å– {len(self.data_list)} ä¸ªèŒä½çš„è¯¦ç»†æè¿°...\")\n",
    "        print(\"   (æ­¤è¿‡ç¨‹è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        for i, item in enumerate(self.data_list):\n",
    "            job_id = item[\"job_id\"]\n",
    "            \n",
    "            print(f\"  ({i+1}/{len(self.data_list)}) æŠ“å–: {item['èŒä½']} - {item['å…¬å¸']}\")\n",
    "            \n",
    "            desc = self.get_job_detail(job_id)\n",
    "            item[\"èŒä½æè¿°\"] = desc\n",
    "            \n",
    "            # *** (æ ¸å¿ƒä¿®æ”¹) ***\n",
    "            # æ‹‰é•¿è¯¦æƒ…é¡µçš„æŠ“å–é—´éš”ï¼Œæ¨¡æ‹Ÿäººç±»ç‚¹å‡»é€Ÿåº¦\n",
    "            sleep_time = random.uniform(3.0, 5.0) \n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "        print(\"\\nâœ… æ‰€æœ‰èŒä½æè¿°æŠ“å–å®Œæ¯•ã€‚\")\n",
    "\n",
    "\n",
    "    def save_excel(self):\n",
    "        \"\"\"ä¿å­˜ä¸º Excel æ–‡ä»¶\"\"\"\n",
    "        if not self.data_list:\n",
    "            print(\"\\nâŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜\")\n",
    "            return\n",
    "        \n",
    "        # (ä¿®æ”¹) åœ¨ä¿å­˜å‰ï¼Œç§»é™¤ä¸´æ—¶çš„ 'job_id' åˆ—\n",
    "        df = pd.DataFrame(self.data_list)\n",
    "        if 'job_id' in df.columns:\n",
    "            df = df.drop(columns=['job_id'])\n",
    "            \n",
    "        filename = f\"é‡‘èžè¡Œä¸šå²—ä½_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "        df.to_excel(filename, index=False)\n",
    "        print(f\"\\nâœ… ä¿å­˜æˆåŠŸï¼š{filename}\")\n",
    "        print(f\"    ðŸ“¦ å…± {len(df)} æ¡èŒä½\")\n",
    "        print(f\"    ðŸ“‹ åŒ…å«åˆ—: {', '.join(df.columns.tolist())}\")\n",
    "\n",
    "    def run(self, keywords=[\"é‡‘èž\"], max_pages_per_kw=3):\n",
    "        \"\"\"\n",
    "        è¿è¡Œçˆ¬è™«\n",
    "        \"\"\"\n",
    "        print(\"ðŸš€ (é˜¶æ®µ1) å¼€å§‹æŠ“å–èŒä½åˆ—è¡¨...\")\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"å…³é”®è¯: {keyword}\")\n",
    "            print('='*60)\n",
    "            self.fetch_data(query=keyword, max_pages=max_pages_per_kw)\n",
    "            \n",
    "            if keyword != keywords[-1]:\n",
    "                time.sleep(random.uniform(3.0, 5.0))\n",
    "        \n",
    "        print(\"\\nðŸ‘ (é˜¶æ®µ1) èŒä½åˆ—è¡¨æŠ“å–å®Œæ¯•ã€‚\")\n",
    "        \n",
    "        # (æ ¸å¿ƒä¿®æ”¹) åœ¨åˆ—è¡¨æŠ“å–å®ŒåŽï¼Œå†ç»Ÿä¸€æŠ“å–è¯¦æƒ…\n",
    "        if self.data_list:\n",
    "            self.fetch_all_details()\n",
    "        \n",
    "        # (æ ¸å¿ƒä¿®æ”¹) æœ€åŽä¿å­˜\n",
    "        self.save_excel()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spider = BossSpiderAPI()\n",
    "    \n",
    "    keywords = [\"é‡‘èž\", \"é“¶è¡Œ\", \"è¯åˆ¸\", \"åŸºé‡‘\", \"ä¿é™©\"]\n",
    "    \n",
    "    # å‡è®¾ä½ æ¯ä¸ªå…³é”®è¯è¦10é¡µ\n",
    "    # spider.run(keywords=keywords, max_pages_per_kw=10) \n",
    "    \n",
    "    # æµ‹è¯•æ—¶ï¼Œå…ˆç”¨å°‘é‡æ•°æ®\n",
    "    spider.run(keywords=keywords[:2], max_pages_per_kw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02709c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ å¼€å§‹æŠ“å–é‡‘èžè¡Œä¸šèŒä½...\n",
      "ðŸ“ é…ç½®: 2 ä¸ªCookie, 1 ä¸ªå…³é”®è¯\n",
      "âš™ï¸  ç­–ç•¥: æ¯é¡µå»¶æ—¶10-20ç§’, è¯¦æƒ…å»¶æ—¶8-15ç§’, æ¯2é¡µåˆ‡æ¢Cookie\n",
      "\n",
      "######################################################################\n",
      "# å…³é”®è¯: é‡‘èž\n",
      "######################################################################\n",
      "ðŸ”¥ æ­£åœ¨é¢„çƒ­è¿žæŽ¥...\n",
      "   ðŸ’¤ é¢„çƒ­å»¶æ—¶ 5.4 ç§’...\n",
      "\n",
      "======================================================================\n",
      "ðŸ” æŠ“å–å…³é”®è¯ [é‡‘èž] ç¬¬ 1 é¡µ...\n",
      "ðŸ“Š å½“å‰ç»Ÿè®¡: å·²é‡‡é›† 0 æ¡ | è¯·æ±‚ 0 æ¬¡\n",
      "======================================================================\n",
      "âš ï¸ è§¦å‘é£ŽæŽ§ (code: 37): æ‚¨çš„è®¿é—®è¡Œä¸ºå¼‚å¸¸.\n",
      "\n",
      "ðŸ’¡ å»ºè®®æ“ä½œï¼š\n",
      "   1. å½“å‰æ•°æ®å·²ä¿å­˜\n",
      "   2. å°è¯•åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªCookieç»§ç»­...\n",
      "ðŸ”„ åˆ‡æ¢åˆ° Cookie #2\n",
      "\n",
      "======================================================================\n",
      "ðŸ” æŠ“å–å…³é”®è¯ [é‡‘èž] ç¬¬ 2 é¡µ...\n",
      "ðŸ“Š å½“å‰ç»Ÿè®¡: å·²é‡‡é›† 0 æ¡ | è¯·æ±‚ 1 æ¬¡\n",
      "======================================================================\n",
      "ðŸ”„ åˆ‡æ¢åˆ° Cookie #1\n",
      "ðŸ’¤ é¡µé¢é—´å»¶æ—¶ 15.9 ç§’...\n",
      "âš ï¸ è§¦å‘é£ŽæŽ§ (code: 37): æ‚¨çš„è®¿é—®è¡Œä¸ºå¼‚å¸¸.\n",
      "\n",
      "ðŸ’¡ å»ºè®®æ“ä½œï¼š\n",
      "   1. å½“å‰æ•°æ®å·²ä¿å­˜\n",
      "   2. å°è¯•åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªCookieç»§ç»­...\n",
      "ðŸ”„ åˆ‡æ¢åˆ° Cookie #2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "class BossSpiderAPI:\n",
    "    def __init__(self):\n",
    "        \"\"\"é‡‘èžè¡Œä¸šèŒä½çˆ¬è™« - ä¼˜åŒ–åçˆ¬ç‰ˆ\"\"\"\n",
    "        self.base_url = \"https://www.zhipin.com/wapi/zpgeek/search/joblist.json\"\n",
    "        self.search_page = \"https://www.zhipin.com/web/geek/job\"\n",
    "        \n",
    "        # ========== æ–¹æ³•2: Cookie è½®æ¢æ± ï¼ˆå‡†å¤‡2-3ä¸ªCookieï¼‰ ==========\n",
    "        self.cookies = [\n",
    "            # Cookie 1: ä»Žæµè§ˆå™¨å¤åˆ¶ç¬¬ä¸€ä¸ªè´¦å·çš„å®Œæ•´Cookie\n",
    "            \"ab_guid=78d319c7-13e6-4a47-baf0-f120a7373d6f; lastCity=100010000; __zp_stoken__=5a4ffw47DvcORCzMIUghlFQtRdEtKZUJla1tISV5sS0xawrxnwp3CrmVlTE7CvsK6wqJewq5aw7NLwqlVwqtRwpbCqMO8wpHCp8K9wpLEkcOgwofEvsOKVMKxwqQxNA8BDw4DfHJ8fXAUCgEADQkXCQgVAA4AAQwyNcO%2FwqPCmzA%2FRD4hVkhWDFVnZk9ZQQ1cTk0zMw4CAgwzKz8%2BMz%2FCucKiwrLDrsOHwqzCs8OjwrvCosK9w6I%2BOz8xwrDDuy47VgPCsRMDFAN0D8K%2Fw7wDw45kI8Krw7%2FCsHQrPzHCvsSyRD4dRDwwODAxOzA%2BLTFFw49mI8K0w7PCscKMID4cOD4wOD4wPjA6PEYiMDkrLj4%2FLjgIDggACSE7wrPCgsKzw5o%2BMA%3D%3D\",\n",
    "            \n",
    "            # Cookie 2: ä»Žæµè§ˆå™¨å¤åˆ¶ç¬¬äºŒä¸ªè´¦å·çš„å®Œæ•´Cookieï¼ˆæ›¿æ¢ä¸ºä½ çš„ç¬¬äºŒä¸ªCookieï¼‰\n",
    "            \"__zp_seo_uuid__=1190494f-f11f-4a57-b5e8-f706bee381e9; __l=r=https%3A%2F%2Fwww.google.com%2F&l=%2F&s=1; __g=-; lastCity=100010000; ab_guid=8dd2897e-0c3e-4151-9bb1-fa78a70c1d18; __zp_stoken__=5a4ffw47Ct8KWCTIIUAtnFHDChBRKQ1VwbE9BwrFgeMKwanXCscK%2BwrDCscKhwqhRwo53wptVwqpOwqNYwr7CqsK6wr3CuMKTw6zCq8KawpnCncK%2BwpDEkMOgwoXEssOsw4TCscKQMjYOAQ0NAX1yfn5yFQoDAw8IFwsLFwEOAgIOMzXDvcKgwpkxP0Y9I1dIVA9XZmZNWkMMXExOMTIOAAEOMis9PTE%2BwrnCoMKxw6zDhsKswrHDoMK5wqPCvcOgPTk%2BMcKyw7gsOlYBwrIRAhQBdw3CvsO8AcONZiLCqMKpYzQwP8K9xLw6MRNHMj5HPjJFPjEjMgzDgVktwrTCqVohMRI6PjFHMDI%2BMUUyRCIxRiwsPj4hRgoOCQ8XIzvCssKNwr3DmD4x; __c=1762957164; __a=91473911.1762957164..1762957164.5.1.5.5\"\n",
    "        ]\n",
    "        self.current_cookie_index = 0\n",
    "        \n",
    "        # ========== æ–¹æ³•4: å¢žå¼ºè¯·æ±‚å¤´æ± ï¼ˆæ›´å¤šæµè§ˆå™¨ç‰¹å¾ï¼‰ ==========\n",
    "        self.user_agents = [\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15\",\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"\n",
    "        ]\n",
    "        \n",
    "        # é‡‘èžç›¸å…³å…³é”®è¯ï¼ˆç”¨äºŽäºŒæ¬¡è¿‡æ»¤ï¼‰\n",
    "        self.finance_pattern = re.compile(\n",
    "            r\"(é‡‘èž|é“¶è¡Œ|åˆ¸å•†|è¯åˆ¸|åŸºé‡‘|ä¿é™©|æœŸè´§|ä¿¡æ‰˜|æŠ•è¡Œ|èµ„ç®¡|ç†è´¢|è´¢å¯Œ|\"\n",
    "            r\"å°è´·|æ¶ˆé‡‘|ä¿ç†|ç§Ÿèµ|å¾ä¿¡|æ¸…ç®—|æ”¯ä»˜|äº’é‡‘|é‡‘èžç§‘æŠ€|FinTech)\",\n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.seen_ids = set()  # åŽ»é‡\n",
    "        self.request_count = 0  # è¯·æ±‚è®¡æ•°\n",
    "\n",
    "    def rotate_cookie(self):\n",
    "        \"\"\"Cookie è½®æ¢ç­–ç•¥\"\"\"\n",
    "        self.current_cookie_index = (self.current_cookie_index + 1) % len(self.cookies)\n",
    "        print(f\"ðŸ”„ åˆ‡æ¢åˆ° Cookie #{self.current_cookie_index + 1}\")\n",
    "\n",
    "    def get_random_headers(self, include_cookie=True):\n",
    "        \"\"\"ç”Ÿæˆéšæœºè¯·æ±‚å¤´ï¼ˆæ–¹æ³•4å¢žå¼ºç‰ˆï¼‰\"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": random.choice(self.user_agents),\n",
    "            \"Referer\": \"https://www.zhipin.com/web/geek/job\",\n",
    "            \"Accept\": \"application/json, text/plain, */*\",\n",
    "            \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "            \"Origin\": \"https://www.zhipin.com\",\n",
    "            \"Sec-Fetch-Dest\": \"empty\",\n",
    "            \"Sec-Fetch-Mode\": \"cors\",\n",
    "            \"Sec-Fetch-Site\": \"same-origin\",\n",
    "            \"sec-ch-ua\": '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "            \"sec-ch-ua-mobile\": \"?0\",\n",
    "            \"sec-ch-ua-platform\": '\"Windows\"',\n",
    "            \"Upgrade-Insecure-Requests\": \"1\"\n",
    "        }\n",
    "        \n",
    "        if include_cookie:\n",
    "            headers[\"Cookie\"] = self.cookies[self.current_cookie_index]\n",
    "        \n",
    "        return headers\n",
    "\n",
    "    def is_finance_related(self, job):\n",
    "        \"\"\"åˆ¤æ–­æ˜¯å¦ä¸ºé‡‘èžç›¸å…³èŒä½\"\"\"\n",
    "        text = \" \".join([\n",
    "            job.get(\"brandIndustry\", \"\") or \"\",\n",
    "            job.get(\"brandName\", \"\") or \"\",\n",
    "            job.get(\"jobName\", \"\") or \"\"\n",
    "        ])\n",
    "        return bool(self.finance_pattern.search(text))\n",
    "\n",
    "    def warmup_session(self, session):\n",
    "        \"\"\"é¢„çƒ­ä¼šè¯ï¼šæ¨¡æ‹ŸçœŸå®žç”¨æˆ·è¡Œä¸º\"\"\"\n",
    "        print(\"ðŸ”¥ æ­£åœ¨é¢„çƒ­è¿žæŽ¥...\")\n",
    "        try:\n",
    "            headers = self.get_random_headers()\n",
    "            _ = session.get(\n",
    "                self.search_page, \n",
    "                headers=headers,\n",
    "                params={\"query\": \"é‡‘èž\", \"city\": \"100010000\"},\n",
    "                timeout=15\n",
    "            )\n",
    "            # æ–¹æ³•1: å¢žåŠ é¢„çƒ­å»¶æ—¶åˆ° 5-8 ç§’\n",
    "            sleep_time = random.uniform(5.0, 8.0)\n",
    "            print(f\"   ðŸ’¤ é¢„çƒ­å»¶æ—¶ {sleep_time:.1f} ç§’...\")\n",
    "            time.sleep(sleep_time)\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ é¢„çƒ­å¤±è´¥ï¼ˆå¯ç»§ç»­ï¼‰: {e}\")\n",
    "\n",
    "    def fetch_data(self, query=\"é‡‘èž\", max_pages=5):\n",
    "        \"\"\"\n",
    "        æŠ“å–èŒä½æ•°æ®ï¼ˆæ–¹æ³•1+2+3ä¼˜åŒ–ç‰ˆï¼‰\n",
    "        \n",
    "        å‚æ•°:\n",
    "            query: æœç´¢å…³é”®è¯\n",
    "            max_pages: æœ€å¤§æŠ“å–é¡µæ•°ï¼ˆå»ºè®®ä¸è¶…è¿‡3ï¼‰\n",
    "        \"\"\"\n",
    "        session = requests.Session()\n",
    "        \n",
    "        # é¢„çƒ­ä¼šè¯\n",
    "        self.warmup_session(session)\n",
    "        \n",
    "        for page in range(1, max_pages + 1):\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"ðŸ” æŠ“å–å…³é”®è¯ [{query}] ç¬¬ {page} é¡µ...\")\n",
    "            print(f\"ðŸ“Š å½“å‰ç»Ÿè®¡: å·²é‡‡é›† {len(self.data_list)} æ¡ | è¯·æ±‚ {self.request_count} æ¬¡\")\n",
    "            print('='*70)\n",
    "            \n",
    "            # ========== æ–¹æ³•2: æ¯2é¡µè½®æ¢ä¸€æ¬¡Cookie ==========\n",
    "            if page > 1 and page % 2 == 0:\n",
    "                self.rotate_cookie()\n",
    "                # Cookieåˆ‡æ¢åŽé¢å¤–å»¶æ—¶\n",
    "                time.sleep(random.uniform(3.0, 5.0))\n",
    "            \n",
    "            # ========== æ–¹æ³•1: é¡µé¢é—´å¤§å¹…å¢žåŠ å»¶æ—¶ï¼ˆ10-20ç§’ï¼‰ ==========\n",
    "            if page > 1:\n",
    "                sleep_time = random.uniform(10.0, 20.0)\n",
    "                print(f\"ðŸ’¤ é¡µé¢é—´å»¶æ—¶ {sleep_time:.1f} ç§’...\")\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            # æž„å»ºè¯·æ±‚å‚æ•°\n",
    "            params = {\n",
    "                \"scene\": \"1\",\n",
    "                \"query\": query,\n",
    "                \"city\": \"100010000\",  # 100010000=åŒ—äº¬, 100000000=å…¨å›½\n",
    "                \"page\": page,\n",
    "                \"pageSize\": 20  # æ–¹æ³•3: é™ä½Žæ¯é¡µæ•°é‡åˆ°20\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                # æ–¹æ³•4: æ¯æ¬¡è¯·æ±‚æ›´æ¢è¯·æ±‚å¤´\n",
    "                headers = self.get_random_headers()\n",
    "                \n",
    "                resp = session.post(\n",
    "                    self.base_url, \n",
    "                    headers=headers, \n",
    "                    data=params,\n",
    "                    timeout=15\n",
    "                )\n",
    "                resp.raise_for_status()\n",
    "                self.request_count += 1\n",
    "                \n",
    "            except requests.RequestException as e:\n",
    "                print(f\"âŒ è¯·æ±‚å¤±è´¥ï¼š{e}\")\n",
    "                # å¤±è´¥åŽå°è¯•åˆ‡æ¢Cookie\n",
    "                self.rotate_cookie()\n",
    "                time.sleep(random.uniform(5.0, 10.0))\n",
    "                continue\n",
    "\n",
    "            # è§£æžå“åº”\n",
    "            try:\n",
    "                result = resp.json()\n",
    "                code = result.get(\"code\")\n",
    "                msg = result.get(\"message\") or result.get(\"msg\")\n",
    "                \n",
    "                if code == 37:\n",
    "                    print(f\"âš ï¸ è§¦å‘é£ŽæŽ§ (code: 37): {msg}\")\n",
    "                    print(\"\\nðŸ’¡ å»ºè®®æ“ä½œï¼š\")\n",
    "                    print(\"   1. å½“å‰æ•°æ®å·²ä¿å­˜\")\n",
    "                    print(\"   2. å°è¯•åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªCookieç»§ç»­...\")\n",
    "                    self.rotate_cookie()\n",
    "                    time.sleep(60)  # ç­‰å¾…1åˆ†é’Ÿ\n",
    "                    continue\n",
    "                    \n",
    "                elif code not in (0, \"0\", None):\n",
    "                    print(f\"âš ï¸ æŽ¥å£å¼‚å¸¸ code: {code}, message: {msg}\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è§£æžå“åº”å¤±è´¥: {e}\")\n",
    "                print(f\"å“åº”å†…å®¹: {resp.text[:300]}\")\n",
    "                continue\n",
    "\n",
    "            # èŽ·å–èŒä½åˆ—è¡¨\n",
    "            job_list = result.get(\"zpData\", {}).get(\"jobList\", [])\n",
    "            \n",
    "            if not job_list:\n",
    "                print(\"âš ï¸ æœ¬é¡µæ— æ•°æ®\")\n",
    "                break\n",
    "            \n",
    "            print(f\"âœ… æœ¬é¡µèŽ·å–åˆ° {len(job_list)} ä¸ªèŒä½\")\n",
    "            \n",
    "            # å¤„ç†æ¯ä¸ªèŒä½\n",
    "            finance_count = 0\n",
    "            for idx, job in enumerate(job_list, 1):\n",
    "                job_id = job.get(\"encryptJobId\")\n",
    "                \n",
    "                # åŽ»é‡\n",
    "                if not job_id or job_id in self.seen_ids:\n",
    "                    continue\n",
    "                \n",
    "                # é‡‘èžè¡Œä¸šè¿‡æ»¤\n",
    "                if not self.is_finance_related(job):\n",
    "                    continue\n",
    "                \n",
    "                finance_count += 1\n",
    "                brand_name = job.get(\"brandName\")\n",
    "                job_name = job.get(\"jobName\")\n",
    "                print(f\"  ðŸ’¼ [{finance_count}] {job_name} - {brand_name}\")\n",
    "                \n",
    "                # èŽ·å–èŒä½è¯¦æƒ…\n",
    "                job_desc = self.get_job_detail(session, job_id)\n",
    "                \n",
    "                # æž„å»ºæ•°æ®é¡¹\n",
    "                item = {\n",
    "                    \"èŒä½\": job_name,\n",
    "                    \"å…¬å¸\": brand_name,\n",
    "                    \"è–ªèµ„\": job.get(\"salaryDesc\"),\n",
    "                    \"åœ°åŒº\": job.get(\"cityName\"),\n",
    "                    \"ç»éªŒ\": job.get(\"jobExperience\"),\n",
    "                    \"å­¦åŽ†\": job.get(\"jobDegree\"),\n",
    "                    \"å…¬å¸è§„æ¨¡\": job.get(\"brandScaleName\"),\n",
    "                    \"è¡Œä¸š\": job.get(\"brandIndustry\"),\n",
    "                    \"ç¦åˆ©æ ‡ç­¾\": \",\".join(job.get(\"welfareList\", []) or []),\n",
    "                    \"æŠ€èƒ½æ ‡ç­¾\": \",\".join(job.get(\"skills\", []) or []),\n",
    "                    \"èŒä½æè¿°\": job_desc\n",
    "                }\n",
    "                \n",
    "                self.data_list.append(item)\n",
    "                self.seen_ids.add(job_id)\n",
    "                \n",
    "                # ========== æ–¹æ³•1: è¯¦æƒ…é¡µå»¶æ—¶å¢žåŠ åˆ° 8-15 ç§’ ==========\n",
    "                sleep_time = random.uniform(8.0, 15.0)\n",
    "                print(f\"       â³ å»¶æ—¶ {sleep_time:.1f} ç§’...\")\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            print(f\"ðŸ“Š æœ¬é¡µç¬¦åˆæ¡ä»¶: {finance_count} ä¸ª | ç´¯è®¡: {len(self.data_list)} ä¸ª\")\n",
    "\n",
    "    def get_job_detail(self, session, job_id):\n",
    "        \"\"\"èŽ·å–èŒä½è¯¦æƒ…æè¿°\"\"\"\n",
    "        if not job_id:\n",
    "            return \"\"\n",
    "        \n",
    "        url = f\"https://www.zhipin.com/job_detail/{job_id}.html\"\n",
    "        try:\n",
    "            # ä½¿ç”¨éšæœºè¯·æ±‚å¤´\n",
    "            headers = self.get_random_headers()\n",
    "            resp = session.get(url, headers=headers, timeout=15)\n",
    "            \n",
    "            if resp.status_code != 200:\n",
    "                return \"\"\n",
    "            \n",
    "            soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "            desc_tag = soup.select_one('.job-sec-text')\n",
    "            return desc_tag.text.strip() if desc_tag else \"\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"       âš ï¸ è¯¦æƒ…é¡µèŽ·å–å¤±è´¥: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def save_excel(self):\n",
    "        \"\"\"ä¿å­˜ä¸º Excel æ–‡ä»¶\"\"\"\n",
    "        if not self.data_list:\n",
    "            print(\"\\nâŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜\")\n",
    "            return\n",
    "        \n",
    "        filename = f\"é‡‘èžè¡Œä¸šå²—ä½_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "        df = pd.DataFrame(self.data_list)\n",
    "        df.to_excel(filename, index=False)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"âœ… ä¿å­˜æˆåŠŸï¼š{filename}\")\n",
    "        print(f\"   ðŸ“¦ å…± {len(df)} æ¡èŒä½ï¼ˆåŽ»é‡åŽï¼‰\")\n",
    "        print(f\"   ðŸ”¢ æ€»è¯·æ±‚æ•°: {self.request_count} æ¬¡\")\n",
    "        print(f\"   ðŸ“‹ åŒ…å«åˆ—: {', '.join(df.columns.tolist())}\")\n",
    "        print('='*70)\n",
    "\n",
    "    def run(self, keywords=[\"é‡‘èž\"], max_pages_per_kw=3):\n",
    "        \"\"\"\n",
    "        è¿è¡Œçˆ¬è™«ï¼ˆæ–¹æ³•3: åˆ†æ‰¹é‡‡é›†ï¼‰\n",
    "        \n",
    "        å‚æ•°:\n",
    "            keywords: å…³é”®è¯åˆ—è¡¨\n",
    "            max_pages_per_kw: æ¯ä¸ªå…³é”®è¯æŠ“å–çš„æœ€å¤§é¡µæ•°ï¼ˆå»ºè®®2-3é¡µï¼‰\n",
    "        \"\"\"\n",
    "        print(\"ðŸš€ å¼€å§‹æŠ“å–é‡‘èžè¡Œä¸šèŒä½...\")\n",
    "        print(f\"ðŸ“ é…ç½®: {len(self.cookies)} ä¸ªCookie, {len(keywords)} ä¸ªå…³é”®è¯\")\n",
    "        print(f\"âš™ï¸  ç­–ç•¥: æ¯é¡µå»¶æ—¶10-20ç§’, è¯¦æƒ…å»¶æ—¶8-15ç§’, æ¯2é¡µåˆ‡æ¢Cookie\")\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            print(f\"\\n{'#'*70}\")\n",
    "            print(f\"# å…³é”®è¯: {keyword}\")\n",
    "            print('#'*70)\n",
    "            \n",
    "            self.fetch_data(query=keyword, max_pages=max_pages_per_kw)\n",
    "            \n",
    "            # ========== æ–¹æ³•3: å…³é”®è¯é—´å¤§å¹…å»¶æ—¶ï¼ˆ30-60ç§’ï¼‰ ==========\n",
    "            if keyword != keywords[-1]:\n",
    "                sleep_time = random.uniform(30.0, 60.0)\n",
    "                print(f\"\\nâ¸ï¸  å…³é”®è¯åˆ‡æ¢ï¼Œä¼‘æ¯ {sleep_time:.1f} ç§’...\")\n",
    "                time.sleep(sleep_time)\n",
    "        \n",
    "        self.save_excel()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spider = BossSpiderAPI()\n",
    "    \n",
    "    # ========== æ–¹æ³•3: åˆ†æ‰¹é‡‡é›†ç­–ç•¥ ==========\n",
    "    # å»ºè®®: é¦–æ¬¡åªçˆ¬1ä¸ªå…³é”®è¯2é¡µï¼Œæµ‹è¯•é€šè¿‡åŽå†å¢žåŠ \n",
    "    keywords = [\"é‡‘èž\"]  # å¯æ‰©å±•: [\"é‡‘èž\", \"é“¶è¡Œ\", \"è¯åˆ¸\"]\n",
    "    \n",
    "    spider.run(keywords=keywords, max_pages_per_kw=2)  # å…ˆæµ‹è¯•2é¡µ\n",
    "    \n",
    "    # å¦‚æžœéœ€è¦æ›´å¤šæ•°æ®ï¼Œé—´éš”30-60åˆ†é’ŸåŽå†è¿è¡Œä¸‹ä¸€æ‰¹\n",
    "    print(\"\\nðŸ’¡ æç¤º: å¦‚éœ€æ›´å¤šæ•°æ®ï¼Œè¯·ç­‰å¾…30-60åˆ†é’ŸåŽå†æ¬¡è¿è¡Œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
